{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a17b416f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T07:54:10.443697Z",
     "iopub.status.busy": "2021-12-09T07:54:10.442221Z",
     "iopub.status.idle": "2021-12-09T07:54:18.934943Z",
     "shell.execute_reply": "2021-12-09T07:54:18.934363Z",
     "shell.execute_reply.started": "2021-12-09T07:23:19.390770Z"
    },
    "id": "iepnmDEU_zyD",
    "outputId": "e8ebd05c-1900-4c17-f44c-1481124dab41",
    "papermill": {
     "duration": 8.500546,
     "end_time": "2021-12-09T07:54:18.935139",
     "exception": false,
     "start_time": "2021-12-09T07:54:10.434593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (1.9.1)\r\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (0.10.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (3.10.0.2)\r\n",
      "Requirement already satisfied: pillow>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision) (8.2.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision) (1.19.5)\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feab52d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-09T07:54:18.973772Z",
     "iopub.status.busy": "2021-12-09T07:54:18.952827Z",
     "iopub.status.idle": "2021-12-09T09:30:30.309279Z",
     "shell.execute_reply": "2021-12-09T09:30:30.309895Z",
     "shell.execute_reply.started": "2021-12-09T07:29:08.925655Z"
    },
    "id": "lJPMmk7Y_2Zn",
    "outputId": "8ed22c2a-46a2-4c79-f23f-880ba75b6fde",
    "papermill": {
     "duration": 5771.369526,
     "end_time": "2021-12-09T09:30:30.310122",
     "exception": false,
     "start_time": "2021-12-09T07:54:18.940596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to drive/app/cifar10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70ff106e947541bba9d47f18db255a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/170498071 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting drive/app/cifar10/cifar-10-python.tar.gz to drive/app/cifar10/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n",
      "Downloading: \"https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\" to /root/.cache/torch/hub/checkpoints/vgg19_bn-c79401a0.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9311ddb0ab46418f9894014a5da6be19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USE 1 GPUs!\n",
      "Epoch: 0 | Batch_idx: 0 |  Loss: (2.3590) | Acc: (15.00%) (6/40)\n",
      "Epoch: 0 | Batch_idx: 10 |  Loss: (2.1180) | Acc: (25.23%) (111/440)\n",
      "Epoch: 0 | Batch_idx: 20 |  Loss: (1.8540) | Acc: (35.00%) (294/840)\n",
      "Epoch: 0 | Batch_idx: 30 |  Loss: (1.5927) | Acc: (43.47%) (539/1240)\n",
      "Epoch: 0 | Batch_idx: 40 |  Loss: (1.4355) | Acc: (49.63%) (814/1640)\n",
      "Epoch: 0 | Batch_idx: 50 |  Loss: (1.3253) | Acc: (53.92%) (1100/2040)\n",
      "Epoch: 0 | Batch_idx: 60 |  Loss: (1.2317) | Acc: (57.01%) (1391/2440)\n",
      "Epoch: 0 | Batch_idx: 70 |  Loss: (1.1598) | Acc: (59.65%) (1694/2840)\n",
      "Epoch: 0 | Batch_idx: 80 |  Loss: (1.1015) | Acc: (61.94%) (2007/3240)\n",
      "Epoch: 0 | Batch_idx: 90 |  Loss: (1.0449) | Acc: (63.96%) (2328/3640)\n",
      "Epoch: 0 | Batch_idx: 100 |  Loss: (1.0028) | Acc: (65.50%) (2646/4040)\n",
      "Epoch: 0 | Batch_idx: 110 |  Loss: (0.9684) | Acc: (66.64%) (2959/4440)\n",
      "Epoch: 0 | Batch_idx: 120 |  Loss: (0.9420) | Acc: (67.77%) (3280/4840)\n",
      "Epoch: 0 | Batch_idx: 130 |  Loss: (0.9085) | Acc: (68.95%) (3613/5240)\n",
      "Epoch: 0 | Batch_idx: 140 |  Loss: (0.8863) | Acc: (69.77%) (3935/5640)\n",
      "Epoch: 0 | Batch_idx: 150 |  Loss: (0.8617) | Acc: (70.65%) (4267/6040)\n",
      "Epoch: 0 | Batch_idx: 160 |  Loss: (0.8337) | Acc: (71.54%) (4607/6440)\n",
      "Epoch: 0 | Batch_idx: 170 |  Loss: (0.8059) | Acc: (72.37%) (4950/6840)\n",
      "Epoch: 0 | Batch_idx: 180 |  Loss: (0.7907) | Acc: (72.96%) (5282/7240)\n",
      "Epoch: 0 | Batch_idx: 190 |  Loss: (0.7745) | Acc: (73.63%) (5625/7640)\n",
      "Epoch: 0 | Batch_idx: 200 |  Loss: (0.7567) | Acc: (74.18%) (5964/8040)\n",
      "Epoch: 0 | Batch_idx: 210 |  Loss: (0.7411) | Acc: (74.72%) (6306/8440)\n",
      "Epoch: 0 | Batch_idx: 220 |  Loss: (0.7240) | Acc: (75.36%) (6662/8840)\n",
      "Epoch: 0 | Batch_idx: 230 |  Loss: (0.7125) | Acc: (75.80%) (7004/9240)\n",
      "Epoch: 0 | Batch_idx: 240 |  Loss: (0.6999) | Acc: (76.24%) (7350/9640)\n",
      "Epoch: 0 | Batch_idx: 250 |  Loss: (0.6870) | Acc: (76.65%) (7696/10040)\n",
      "Epoch: 0 | Batch_idx: 260 |  Loss: (0.6783) | Acc: (76.93%) (8032/10440)\n",
      "Epoch: 0 | Batch_idx: 270 |  Loss: (0.6707) | Acc: (77.22%) (8371/10840)\n",
      "Epoch: 0 | Batch_idx: 280 |  Loss: (0.6591) | Acc: (77.67%) (8730/11240)\n",
      "Epoch: 0 | Batch_idx: 290 |  Loss: (0.6500) | Acc: (77.96%) (9074/11640)\n",
      "Epoch: 0 | Batch_idx: 300 |  Loss: (0.6408) | Acc: (78.27%) (9424/12040)\n",
      "Epoch: 0 | Batch_idx: 310 |  Loss: (0.6312) | Acc: (78.61%) (9779/12440)\n",
      "Epoch: 0 | Batch_idx: 320 |  Loss: (0.6231) | Acc: (78.89%) (10130/12840)\n",
      "Epoch: 0 | Batch_idx: 330 |  Loss: (0.6129) | Acc: (79.21%) (10488/13240)\n",
      "Epoch: 0 | Batch_idx: 340 |  Loss: (0.6061) | Acc: (79.49%) (10843/13640)\n",
      "Epoch: 0 | Batch_idx: 350 |  Loss: (0.5979) | Acc: (79.76%) (11198/14040)\n",
      "Epoch: 0 | Batch_idx: 360 |  Loss: (0.5912) | Acc: (79.97%) (11548/14440)\n",
      "Epoch: 0 | Batch_idx: 370 |  Loss: (0.5831) | Acc: (80.24%) (11907/14840)\n",
      "Epoch: 0 | Batch_idx: 380 |  Loss: (0.5766) | Acc: (80.47%) (12264/15240)\n",
      "Epoch: 0 | Batch_idx: 390 |  Loss: (0.5685) | Acc: (80.73%) (12626/15640)\n",
      "Epoch: 0 | Batch_idx: 400 |  Loss: (0.5615) | Acc: (80.97%) (12987/16040)\n",
      "Epoch: 0 | Batch_idx: 410 |  Loss: (0.5536) | Acc: (81.23%) (13354/16440)\n",
      "Epoch: 0 | Batch_idx: 420 |  Loss: (0.5453) | Acc: (81.50%) (13725/16840)\n",
      "Epoch: 0 | Batch_idx: 430 |  Loss: (0.5397) | Acc: (81.66%) (14078/17240)\n",
      "Epoch: 0 | Batch_idx: 440 |  Loss: (0.5353) | Acc: (81.80%) (14429/17640)\n",
      "Epoch: 0 | Batch_idx: 450 |  Loss: (0.5292) | Acc: (82.00%) (14793/18040)\n",
      "Epoch: 0 | Batch_idx: 460 |  Loss: (0.5246) | Acc: (82.18%) (15154/18440)\n",
      "Epoch: 0 | Batch_idx: 470 |  Loss: (0.5197) | Acc: (82.35%) (15514/18840)\n",
      "Epoch: 0 | Batch_idx: 480 |  Loss: (0.5154) | Acc: (82.47%) (15868/19240)\n",
      "Epoch: 0 | Batch_idx: 490 |  Loss: (0.5118) | Acc: (82.65%) (16232/19640)\n",
      "Epoch: 0 | Batch_idx: 500 |  Loss: (0.5080) | Acc: (82.79%) (16591/20040)\n",
      "Epoch: 0 | Batch_idx: 510 |  Loss: (0.5033) | Acc: (82.94%) (16953/20440)\n",
      "Epoch: 0 | Batch_idx: 520 |  Loss: (0.4996) | Acc: (83.04%) (17306/20840)\n",
      "Epoch: 0 | Batch_idx: 530 |  Loss: (0.4954) | Acc: (83.19%) (17669/21240)\n",
      "Epoch: 0 | Batch_idx: 540 |  Loss: (0.4925) | Acc: (83.32%) (18031/21640)\n",
      "Epoch: 0 | Batch_idx: 550 |  Loss: (0.4884) | Acc: (83.46%) (18395/22040)\n",
      "Epoch: 0 | Batch_idx: 560 |  Loss: (0.4853) | Acc: (83.55%) (18748/22440)\n",
      "Epoch: 0 | Batch_idx: 570 |  Loss: (0.4810) | Acc: (83.69%) (19114/22840)\n",
      "Epoch: 0 | Batch_idx: 580 |  Loss: (0.4769) | Acc: (83.82%) (19480/23240)\n",
      "Epoch: 0 | Batch_idx: 590 |  Loss: (0.4735) | Acc: (83.96%) (19848/23640)\n",
      "Epoch: 0 | Batch_idx: 600 |  Loss: (0.4695) | Acc: (84.08%) (20214/24040)\n",
      "Epoch: 0 | Batch_idx: 610 |  Loss: (0.4665) | Acc: (84.20%) (20578/24440)\n",
      "Epoch: 0 | Batch_idx: 620 |  Loss: (0.4630) | Acc: (84.32%) (20944/24840)\n",
      "Epoch: 0 | Batch_idx: 630 |  Loss: (0.4601) | Acc: (84.43%) (21310/25240)\n",
      "Epoch: 0 | Batch_idx: 640 |  Loss: (0.4561) | Acc: (84.56%) (21680/25640)\n",
      "Epoch: 0 | Batch_idx: 650 |  Loss: (0.4531) | Acc: (84.67%) (22048/26040)\n",
      "Epoch: 0 | Batch_idx: 660 |  Loss: (0.4498) | Acc: (84.79%) (22419/26440)\n",
      "Epoch: 0 | Batch_idx: 670 |  Loss: (0.4472) | Acc: (84.88%) (22781/26840)\n",
      "Epoch: 0 | Batch_idx: 680 |  Loss: (0.4444) | Acc: (84.98%) (23149/27240)\n",
      "Epoch: 0 | Batch_idx: 690 |  Loss: (0.4417) | Acc: (85.06%) (23510/27640)\n",
      "Epoch: 0 | Batch_idx: 700 |  Loss: (0.4394) | Acc: (85.14%) (23872/28040)\n",
      "Epoch: 0 | Batch_idx: 710 |  Loss: (0.4372) | Acc: (85.22%) (24237/28440)\n",
      "Epoch: 0 | Batch_idx: 720 |  Loss: (0.4343) | Acc: (85.31%) (24604/28840)\n",
      "Epoch: 0 | Batch_idx: 730 |  Loss: (0.4320) | Acc: (85.40%) (24971/29240)\n",
      "Epoch: 0 | Batch_idx: 740 |  Loss: (0.4292) | Acc: (85.49%) (25340/29640)\n",
      "Epoch: 0 | Batch_idx: 750 |  Loss: (0.4281) | Acc: (85.52%) (25690/30040)\n",
      "Epoch: 0 | Batch_idx: 760 |  Loss: (0.4257) | Acc: (85.60%) (26056/30440)\n",
      "Epoch: 0 | Batch_idx: 770 |  Loss: (0.4231) | Acc: (85.68%) (26424/30840)\n",
      "Epoch: 0 | Batch_idx: 780 |  Loss: (0.4210) | Acc: (85.75%) (26787/31240)\n",
      "Epoch: 0 | Batch_idx: 790 |  Loss: (0.4186) | Acc: (85.83%) (27156/31640)\n",
      "Epoch: 0 | Batch_idx: 800 |  Loss: (0.4169) | Acc: (85.89%) (27519/32040)\n",
      "Epoch: 0 | Batch_idx: 810 |  Loss: (0.4146) | Acc: (85.98%) (27892/32440)\n",
      "Epoch: 0 | Batch_idx: 820 |  Loss: (0.4121) | Acc: (86.06%) (28261/32840)\n",
      "Epoch: 0 | Batch_idx: 830 |  Loss: (0.4098) | Acc: (86.13%) (28631/33240)\n",
      "Epoch: 0 | Batch_idx: 840 |  Loss: (0.4084) | Acc: (86.20%) (28997/33640)\n",
      "Epoch: 0 | Batch_idx: 850 |  Loss: (0.4060) | Acc: (86.29%) (29372/34040)\n",
      "Epoch: 0 | Batch_idx: 860 |  Loss: (0.4040) | Acc: (86.36%) (29744/34440)\n",
      "Epoch: 0 | Batch_idx: 870 |  Loss: (0.4031) | Acc: (86.39%) (30098/34840)\n",
      "Epoch: 0 | Batch_idx: 880 |  Loss: (0.4011) | Acc: (86.45%) (30464/35240)\n",
      "Epoch: 0 | Batch_idx: 890 |  Loss: (0.3993) | Acc: (86.50%) (30830/35640)\n",
      "Epoch: 0 | Batch_idx: 900 |  Loss: (0.3977) | Acc: (86.56%) (31196/36040)\n",
      "Epoch: 0 | Batch_idx: 910 |  Loss: (0.3961) | Acc: (86.62%) (31566/36440)\n",
      "Epoch: 0 | Batch_idx: 920 |  Loss: (0.3942) | Acc: (86.69%) (31938/36840)\n",
      "Epoch: 0 | Batch_idx: 930 |  Loss: (0.3920) | Acc: (86.77%) (32315/37240)\n",
      "Epoch: 0 | Batch_idx: 940 |  Loss: (0.3894) | Acc: (86.85%) (32692/37640)\n",
      "Epoch: 0 | Batch_idx: 950 |  Loss: (0.3877) | Acc: (86.92%) (33063/38040)\n",
      "Epoch: 0 | Batch_idx: 960 |  Loss: (0.3860) | Acc: (86.97%) (33433/38440)\n",
      "Epoch: 0 | Batch_idx: 970 |  Loss: (0.3836) | Acc: (87.05%) (33810/38840)\n",
      "Epoch: 0 | Batch_idx: 980 |  Loss: (0.3819) | Acc: (87.11%) (34182/39240)\n",
      "Epoch: 0 | Batch_idx: 990 |  Loss: (0.3802) | Acc: (87.16%) (34551/39640)\n",
      "Epoch: 0 | Batch_idx: 1000 |  Loss: (0.3783) | Acc: (87.22%) (34924/40040)\n",
      "Epoch: 0 | Batch_idx: 1010 |  Loss: (0.3766) | Acc: (87.29%) (35300/40440)\n",
      "Epoch: 0 | Batch_idx: 1020 |  Loss: (0.3758) | Acc: (87.32%) (35663/40840)\n",
      "Epoch: 0 | Batch_idx: 1030 |  Loss: (0.3744) | Acc: (87.35%) (36022/41240)\n",
      "Epoch: 0 | Batch_idx: 1040 |  Loss: (0.3729) | Acc: (87.40%) (36392/41640)\n",
      "Epoch: 0 | Batch_idx: 1050 |  Loss: (0.3714) | Acc: (87.45%) (36766/42040)\n",
      "Epoch: 0 | Batch_idx: 1060 |  Loss: (0.3703) | Acc: (87.47%) (37123/42440)\n",
      "Epoch: 0 | Batch_idx: 1070 |  Loss: (0.3687) | Acc: (87.53%) (37497/42840)\n",
      "Epoch: 0 | Batch_idx: 1080 |  Loss: (0.3672) | Acc: (87.59%) (37872/43240)\n",
      "Epoch: 0 | Batch_idx: 1090 |  Loss: (0.3651) | Acc: (87.66%) (38253/43640)\n",
      "Epoch: 0 | Batch_idx: 1100 |  Loss: (0.3641) | Acc: (87.70%) (38623/44040)\n",
      "Epoch: 0 | Batch_idx: 1110 |  Loss: (0.3629) | Acc: (87.75%) (38996/44440)\n",
      "Epoch: 0 | Batch_idx: 1120 |  Loss: (0.3612) | Acc: (87.81%) (39372/44840)\n",
      "Epoch: 0 | Batch_idx: 1130 |  Loss: (0.3597) | Acc: (87.86%) (39748/45240)\n",
      "Epoch: 0 | Batch_idx: 1140 |  Loss: (0.3587) | Acc: (87.91%) (40121/45640)\n",
      "Epoch: 0 | Batch_idx: 1150 |  Loss: (0.3577) | Acc: (87.94%) (40487/46040)\n",
      "Epoch: 0 | Batch_idx: 1160 |  Loss: (0.3571) | Acc: (87.95%) (40845/46440)\n",
      "Epoch: 0 | Batch_idx: 1170 |  Loss: (0.3562) | Acc: (87.99%) (41214/46840)\n",
      "Epoch: 0 | Batch_idx: 1180 |  Loss: (0.3546) | Acc: (88.04%) (41592/47240)\n",
      "Epoch: 0 | Batch_idx: 1190 |  Loss: (0.3530) | Acc: (88.10%) (41973/47640)\n",
      "Epoch: 0 | Batch_idx: 1200 |  Loss: (0.3520) | Acc: (88.15%) (42349/48040)\n",
      "Epoch: 0 | Batch_idx: 1210 |  Loss: (0.3505) | Acc: (88.20%) (42722/48440)\n",
      "Epoch: 0 | Batch_idx: 1220 |  Loss: (0.3490) | Acc: (88.24%) (43097/48840)\n",
      "Epoch: 0 | Batch_idx: 1230 |  Loss: (0.3473) | Acc: (88.30%) (43479/49240)\n",
      "Epoch: 0 | Batch_idx: 1240 |  Loss: (0.3465) | Acc: (88.33%) (43848/49640)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.1864) | Acc: (93.72%) (9372/10000)\n",
      "Epoch: 1 | Batch_idx: 0 |  Loss: (0.2281) | Acc: (92.50%) (37/40)\n",
      "Epoch: 1 | Batch_idx: 10 |  Loss: (0.1400) | Acc: (96.36%) (424/440)\n",
      "Epoch: 1 | Batch_idx: 20 |  Loss: (0.1363) | Acc: (96.07%) (807/840)\n",
      "Epoch: 1 | Batch_idx: 30 |  Loss: (0.1413) | Acc: (95.97%) (1190/1240)\n",
      "Epoch: 1 | Batch_idx: 40 |  Loss: (0.1337) | Acc: (96.04%) (1575/1640)\n",
      "Epoch: 1 | Batch_idx: 50 |  Loss: (0.1421) | Acc: (95.64%) (1951/2040)\n",
      "Epoch: 1 | Batch_idx: 60 |  Loss: (0.1362) | Acc: (95.78%) (2337/2440)\n",
      "Epoch: 1 | Batch_idx: 70 |  Loss: (0.1317) | Acc: (95.74%) (2719/2840)\n",
      "Epoch: 1 | Batch_idx: 80 |  Loss: (0.1304) | Acc: (95.93%) (3108/3240)\n",
      "Epoch: 1 | Batch_idx: 90 |  Loss: (0.1306) | Acc: (95.91%) (3491/3640)\n",
      "Epoch: 1 | Batch_idx: 100 |  Loss: (0.1303) | Acc: (95.84%) (3872/4040)\n",
      "Epoch: 1 | Batch_idx: 110 |  Loss: (0.1309) | Acc: (95.74%) (4251/4440)\n",
      "Epoch: 1 | Batch_idx: 120 |  Loss: (0.1312) | Acc: (95.66%) (4630/4840)\n",
      "Epoch: 1 | Batch_idx: 130 |  Loss: (0.1277) | Acc: (95.78%) (5019/5240)\n",
      "Epoch: 1 | Batch_idx: 140 |  Loss: (0.1265) | Acc: (95.78%) (5402/5640)\n",
      "Epoch: 1 | Batch_idx: 150 |  Loss: (0.1236) | Acc: (95.83%) (5788/6040)\n",
      "Epoch: 1 | Batch_idx: 160 |  Loss: (0.1266) | Acc: (95.68%) (6162/6440)\n",
      "Epoch: 1 | Batch_idx: 170 |  Loss: (0.1266) | Acc: (95.69%) (6545/6840)\n",
      "Epoch: 1 | Batch_idx: 180 |  Loss: (0.1263) | Acc: (95.73%) (6931/7240)\n",
      "Epoch: 1 | Batch_idx: 190 |  Loss: (0.1261) | Acc: (95.72%) (7313/7640)\n",
      "Epoch: 1 | Batch_idx: 200 |  Loss: (0.1256) | Acc: (95.75%) (7698/8040)\n",
      "Epoch: 1 | Batch_idx: 210 |  Loss: (0.1237) | Acc: (95.82%) (8087/8440)\n",
      "Epoch: 1 | Batch_idx: 220 |  Loss: (0.1232) | Acc: (95.84%) (8472/8840)\n",
      "Epoch: 1 | Batch_idx: 230 |  Loss: (0.1243) | Acc: (95.83%) (8855/9240)\n",
      "Epoch: 1 | Batch_idx: 240 |  Loss: (0.1246) | Acc: (95.84%) (9239/9640)\n",
      "Epoch: 1 | Batch_idx: 250 |  Loss: (0.1230) | Acc: (95.89%) (9627/10040)\n",
      "Epoch: 1 | Batch_idx: 260 |  Loss: (0.1235) | Acc: (95.87%) (10009/10440)\n",
      "Epoch: 1 | Batch_idx: 270 |  Loss: (0.1237) | Acc: (95.86%) (10391/10840)\n",
      "Epoch: 1 | Batch_idx: 280 |  Loss: (0.1260) | Acc: (95.80%) (10768/11240)\n",
      "Epoch: 1 | Batch_idx: 290 |  Loss: (0.1278) | Acc: (95.75%) (11145/11640)\n",
      "Epoch: 1 | Batch_idx: 300 |  Loss: (0.1270) | Acc: (95.76%) (11529/12040)\n",
      "Epoch: 1 | Batch_idx: 310 |  Loss: (0.1259) | Acc: (95.77%) (11914/12440)\n",
      "Epoch: 1 | Batch_idx: 320 |  Loss: (0.1252) | Acc: (95.80%) (12301/12840)\n",
      "Epoch: 1 | Batch_idx: 330 |  Loss: (0.1255) | Acc: (95.79%) (12683/13240)\n",
      "Epoch: 1 | Batch_idx: 340 |  Loss: (0.1253) | Acc: (95.78%) (13064/13640)\n",
      "Epoch: 1 | Batch_idx: 350 |  Loss: (0.1252) | Acc: (95.79%) (13449/14040)\n",
      "Epoch: 1 | Batch_idx: 360 |  Loss: (0.1246) | Acc: (95.81%) (13835/14440)\n",
      "Epoch: 1 | Batch_idx: 370 |  Loss: (0.1252) | Acc: (95.81%) (14218/14840)\n",
      "Epoch: 1 | Batch_idx: 380 |  Loss: (0.1248) | Acc: (95.81%) (14602/15240)\n",
      "Epoch: 1 | Batch_idx: 390 |  Loss: (0.1239) | Acc: (95.84%) (14989/15640)\n",
      "Epoch: 1 | Batch_idx: 400 |  Loss: (0.1248) | Acc: (95.84%) (15372/16040)\n",
      "Epoch: 1 | Batch_idx: 410 |  Loss: (0.1245) | Acc: (95.85%) (15757/16440)\n",
      "Epoch: 1 | Batch_idx: 420 |  Loss: (0.1249) | Acc: (95.83%) (16137/16840)\n",
      "Epoch: 1 | Batch_idx: 430 |  Loss: (0.1247) | Acc: (95.84%) (16522/17240)\n",
      "Epoch: 1 | Batch_idx: 440 |  Loss: (0.1238) | Acc: (95.87%) (16911/17640)\n",
      "Epoch: 1 | Batch_idx: 450 |  Loss: (0.1233) | Acc: (95.89%) (17298/18040)\n",
      "Epoch: 1 | Batch_idx: 460 |  Loss: (0.1226) | Acc: (95.91%) (17686/18440)\n",
      "Epoch: 1 | Batch_idx: 470 |  Loss: (0.1230) | Acc: (95.89%) (18065/18840)\n",
      "Epoch: 1 | Batch_idx: 480 |  Loss: (0.1241) | Acc: (95.87%) (18445/19240)\n",
      "Epoch: 1 | Batch_idx: 490 |  Loss: (0.1246) | Acc: (95.87%) (18828/19640)\n",
      "Epoch: 1 | Batch_idx: 500 |  Loss: (0.1236) | Acc: (95.90%) (19218/20040)\n",
      "Epoch: 1 | Batch_idx: 510 |  Loss: (0.1241) | Acc: (95.88%) (19598/20440)\n",
      "Epoch: 1 | Batch_idx: 520 |  Loss: (0.1233) | Acc: (95.91%) (19988/20840)\n",
      "Epoch: 1 | Batch_idx: 530 |  Loss: (0.1236) | Acc: (95.93%) (20375/21240)\n",
      "Epoch: 1 | Batch_idx: 540 |  Loss: (0.1239) | Acc: (95.92%) (20757/21640)\n",
      "Epoch: 1 | Batch_idx: 550 |  Loss: (0.1235) | Acc: (95.92%) (21141/22040)\n",
      "Epoch: 1 | Batch_idx: 560 |  Loss: (0.1229) | Acc: (95.93%) (21527/22440)\n",
      "Epoch: 1 | Batch_idx: 570 |  Loss: (0.1233) | Acc: (95.91%) (21906/22840)\n",
      "Epoch: 1 | Batch_idx: 580 |  Loss: (0.1227) | Acc: (95.95%) (22298/23240)\n",
      "Epoch: 1 | Batch_idx: 590 |  Loss: (0.1223) | Acc: (95.97%) (22688/23640)\n",
      "Epoch: 1 | Batch_idx: 600 |  Loss: (0.1224) | Acc: (95.97%) (23072/24040)\n",
      "Epoch: 1 | Batch_idx: 610 |  Loss: (0.1222) | Acc: (95.98%) (23457/24440)\n",
      "Epoch: 1 | Batch_idx: 620 |  Loss: (0.1217) | Acc: (96.00%) (23846/24840)\n",
      "Epoch: 1 | Batch_idx: 630 |  Loss: (0.1221) | Acc: (95.98%) (24226/25240)\n",
      "Epoch: 1 | Batch_idx: 640 |  Loss: (0.1216) | Acc: (96.01%) (24616/25640)\n",
      "Epoch: 1 | Batch_idx: 650 |  Loss: (0.1219) | Acc: (95.98%) (24992/26040)\n",
      "Epoch: 1 | Batch_idx: 660 |  Loss: (0.1221) | Acc: (95.98%) (25377/26440)\n",
      "Epoch: 1 | Batch_idx: 670 |  Loss: (0.1217) | Acc: (95.99%) (25764/26840)\n",
      "Epoch: 1 | Batch_idx: 680 |  Loss: (0.1218) | Acc: (95.98%) (26144/27240)\n",
      "Epoch: 1 | Batch_idx: 690 |  Loss: (0.1220) | Acc: (95.95%) (26521/27640)\n",
      "Epoch: 1 | Batch_idx: 700 |  Loss: (0.1214) | Acc: (95.97%) (26910/28040)\n",
      "Epoch: 1 | Batch_idx: 710 |  Loss: (0.1213) | Acc: (95.96%) (27290/28440)\n",
      "Epoch: 1 | Batch_idx: 720 |  Loss: (0.1213) | Acc: (95.95%) (27673/28840)\n",
      "Epoch: 1 | Batch_idx: 730 |  Loss: (0.1211) | Acc: (95.96%) (28060/29240)\n",
      "Epoch: 1 | Batch_idx: 740 |  Loss: (0.1219) | Acc: (95.95%) (28439/29640)\n",
      "Epoch: 1 | Batch_idx: 750 |  Loss: (0.1217) | Acc: (95.96%) (28826/30040)\n",
      "Epoch: 1 | Batch_idx: 760 |  Loss: (0.1215) | Acc: (95.96%) (29211/30440)\n",
      "Epoch: 1 | Batch_idx: 770 |  Loss: (0.1207) | Acc: (95.99%) (29604/30840)\n",
      "Epoch: 1 | Batch_idx: 780 |  Loss: (0.1201) | Acc: (96.00%) (29989/31240)\n",
      "Epoch: 1 | Batch_idx: 790 |  Loss: (0.1204) | Acc: (95.99%) (30371/31640)\n",
      "Epoch: 1 | Batch_idx: 800 |  Loss: (0.1202) | Acc: (96.00%) (30757/32040)\n",
      "Epoch: 1 | Batch_idx: 810 |  Loss: (0.1199) | Acc: (96.01%) (31145/32440)\n",
      "Epoch: 1 | Batch_idx: 820 |  Loss: (0.1206) | Acc: (95.98%) (31520/32840)\n",
      "Epoch: 1 | Batch_idx: 830 |  Loss: (0.1209) | Acc: (95.97%) (31900/33240)\n",
      "Epoch: 1 | Batch_idx: 840 |  Loss: (0.1203) | Acc: (95.99%) (32290/33640)\n",
      "Epoch: 1 | Batch_idx: 850 |  Loss: (0.1203) | Acc: (96.00%) (32677/34040)\n",
      "Epoch: 1 | Batch_idx: 860 |  Loss: (0.1199) | Acc: (96.01%) (33066/34440)\n",
      "Epoch: 1 | Batch_idx: 870 |  Loss: (0.1194) | Acc: (96.03%) (33458/34840)\n",
      "Epoch: 1 | Batch_idx: 880 |  Loss: (0.1192) | Acc: (96.05%) (33847/35240)\n",
      "Epoch: 1 | Batch_idx: 890 |  Loss: (0.1188) | Acc: (96.06%) (34237/35640)\n",
      "Epoch: 1 | Batch_idx: 900 |  Loss: (0.1184) | Acc: (96.08%) (34628/36040)\n",
      "Epoch: 1 | Batch_idx: 910 |  Loss: (0.1181) | Acc: (96.08%) (35012/36440)\n",
      "Epoch: 1 | Batch_idx: 920 |  Loss: (0.1178) | Acc: (96.09%) (35399/36840)\n",
      "Epoch: 1 | Batch_idx: 930 |  Loss: (0.1175) | Acc: (96.10%) (35789/37240)\n",
      "Epoch: 1 | Batch_idx: 940 |  Loss: (0.1180) | Acc: (96.08%) (36163/37640)\n",
      "Epoch: 1 | Batch_idx: 950 |  Loss: (0.1180) | Acc: (96.07%) (36545/38040)\n",
      "Epoch: 1 | Batch_idx: 960 |  Loss: (0.1177) | Acc: (96.07%) (36929/38440)\n",
      "Epoch: 1 | Batch_idx: 970 |  Loss: (0.1177) | Acc: (96.07%) (37312/38840)\n",
      "Epoch: 1 | Batch_idx: 980 |  Loss: (0.1169) | Acc: (96.09%) (37705/39240)\n",
      "Epoch: 1 | Batch_idx: 990 |  Loss: (0.1166) | Acc: (96.09%) (38090/39640)\n",
      "Epoch: 1 | Batch_idx: 1000 |  Loss: (0.1166) | Acc: (96.10%) (38477/40040)\n",
      "Epoch: 1 | Batch_idx: 1010 |  Loss: (0.1164) | Acc: (96.11%) (38865/40440)\n",
      "Epoch: 1 | Batch_idx: 1020 |  Loss: (0.1168) | Acc: (96.08%) (39240/40840)\n",
      "Epoch: 1 | Batch_idx: 1030 |  Loss: (0.1170) | Acc: (96.07%) (39619/41240)\n",
      "Epoch: 1 | Batch_idx: 1040 |  Loss: (0.1168) | Acc: (96.08%) (40008/41640)\n",
      "Epoch: 1 | Batch_idx: 1050 |  Loss: (0.1168) | Acc: (96.08%) (40393/42040)\n",
      "Epoch: 1 | Batch_idx: 1060 |  Loss: (0.1168) | Acc: (96.08%) (40778/42440)\n",
      "Epoch: 1 | Batch_idx: 1070 |  Loss: (0.1167) | Acc: (96.09%) (41163/42840)\n",
      "Epoch: 1 | Batch_idx: 1080 |  Loss: (0.1165) | Acc: (96.09%) (41548/43240)\n",
      "Epoch: 1 | Batch_idx: 1090 |  Loss: (0.1168) | Acc: (96.09%) (41932/43640)\n",
      "Epoch: 1 | Batch_idx: 1100 |  Loss: (0.1166) | Acc: (96.10%) (42323/44040)\n",
      "Epoch: 1 | Batch_idx: 1110 |  Loss: (0.1162) | Acc: (96.12%) (42715/44440)\n",
      "Epoch: 1 | Batch_idx: 1120 |  Loss: (0.1161) | Acc: (96.12%) (43100/44840)\n",
      "Epoch: 1 | Batch_idx: 1130 |  Loss: (0.1160) | Acc: (96.13%) (43489/45240)\n",
      "Epoch: 1 | Batch_idx: 1140 |  Loss: (0.1161) | Acc: (96.12%) (43870/45640)\n",
      "Epoch: 1 | Batch_idx: 1150 |  Loss: (0.1162) | Acc: (96.12%) (44254/46040)\n",
      "Epoch: 1 | Batch_idx: 1160 |  Loss: (0.1160) | Acc: (96.13%) (44642/46440)\n",
      "Epoch: 1 | Batch_idx: 1170 |  Loss: (0.1162) | Acc: (96.13%) (45026/46840)\n",
      "Epoch: 1 | Batch_idx: 1180 |  Loss: (0.1160) | Acc: (96.14%) (45416/47240)\n",
      "Epoch: 1 | Batch_idx: 1190 |  Loss: (0.1162) | Acc: (96.15%) (45804/47640)\n",
      "Epoch: 1 | Batch_idx: 1200 |  Loss: (0.1165) | Acc: (96.14%) (46184/48040)\n",
      "Epoch: 1 | Batch_idx: 1210 |  Loss: (0.1161) | Acc: (96.15%) (46574/48440)\n",
      "Epoch: 1 | Batch_idx: 1220 |  Loss: (0.1162) | Acc: (96.15%) (46958/48840)\n",
      "Epoch: 1 | Batch_idx: 1230 |  Loss: (0.1159) | Acc: (96.15%) (47343/49240)\n",
      "Epoch: 1 | Batch_idx: 1240 |  Loss: (0.1161) | Acc: (96.14%) (47725/49640)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.1527) | Acc: (94.88%) (9488/10000)\n",
      "Epoch: 2 | Batch_idx: 0 |  Loss: (0.0225) | Acc: (100.00%) (40/40)\n",
      "Epoch: 2 | Batch_idx: 10 |  Loss: (0.0516) | Acc: (98.41%) (433/440)\n",
      "Epoch: 2 | Batch_idx: 20 |  Loss: (0.0686) | Acc: (97.62%) (820/840)\n",
      "Epoch: 2 | Batch_idx: 30 |  Loss: (0.0639) | Acc: (97.90%) (1214/1240)\n",
      "Epoch: 2 | Batch_idx: 40 |  Loss: (0.0629) | Acc: (97.99%) (1607/1640)\n",
      "Epoch: 2 | Batch_idx: 50 |  Loss: (0.0634) | Acc: (97.84%) (1996/2040)\n",
      "Epoch: 2 | Batch_idx: 60 |  Loss: (0.0642) | Acc: (97.75%) (2385/2440)\n",
      "Epoch: 2 | Batch_idx: 70 |  Loss: (0.0647) | Acc: (97.78%) (2777/2840)\n",
      "Epoch: 2 | Batch_idx: 80 |  Loss: (0.0642) | Acc: (97.78%) (3168/3240)\n",
      "Epoch: 2 | Batch_idx: 90 |  Loss: (0.0638) | Acc: (97.83%) (3561/3640)\n",
      "Epoch: 2 | Batch_idx: 100 |  Loss: (0.0650) | Acc: (97.80%) (3951/4040)\n",
      "Epoch: 2 | Batch_idx: 110 |  Loss: (0.0640) | Acc: (97.84%) (4344/4440)\n",
      "Epoch: 2 | Batch_idx: 120 |  Loss: (0.0652) | Acc: (97.81%) (4734/4840)\n",
      "Epoch: 2 | Batch_idx: 130 |  Loss: (0.0664) | Acc: (97.75%) (5122/5240)\n",
      "Epoch: 2 | Batch_idx: 140 |  Loss: (0.0664) | Acc: (97.75%) (5513/5640)\n",
      "Epoch: 2 | Batch_idx: 150 |  Loss: (0.0660) | Acc: (97.76%) (5905/6040)\n",
      "Epoch: 2 | Batch_idx: 160 |  Loss: (0.0681) | Acc: (97.66%) (6289/6440)\n",
      "Epoch: 2 | Batch_idx: 170 |  Loss: (0.0690) | Acc: (97.60%) (6676/6840)\n",
      "Epoch: 2 | Batch_idx: 180 |  Loss: (0.0704) | Acc: (97.61%) (7067/7240)\n",
      "Epoch: 2 | Batch_idx: 190 |  Loss: (0.0690) | Acc: (97.68%) (7463/7640)\n",
      "Epoch: 2 | Batch_idx: 200 |  Loss: (0.0690) | Acc: (97.70%) (7855/8040)\n",
      "Epoch: 2 | Batch_idx: 210 |  Loss: (0.0678) | Acc: (97.75%) (8250/8440)\n",
      "Epoch: 2 | Batch_idx: 220 |  Loss: (0.0686) | Acc: (97.69%) (8636/8840)\n",
      "Epoch: 2 | Batch_idx: 230 |  Loss: (0.0676) | Acc: (97.73%) (9030/9240)\n",
      "Epoch: 2 | Batch_idx: 240 |  Loss: (0.0689) | Acc: (97.72%) (9420/9640)\n",
      "Epoch: 2 | Batch_idx: 250 |  Loss: (0.0681) | Acc: (97.77%) (9816/10040)\n",
      "Epoch: 2 | Batch_idx: 260 |  Loss: (0.0667) | Acc: (97.81%) (10211/10440)\n",
      "Epoch: 2 | Batch_idx: 270 |  Loss: (0.0663) | Acc: (97.80%) (10601/10840)\n",
      "Epoch: 2 | Batch_idx: 280 |  Loss: (0.0657) | Acc: (97.83%) (10996/11240)\n",
      "Epoch: 2 | Batch_idx: 290 |  Loss: (0.0656) | Acc: (97.86%) (11391/11640)\n",
      "Epoch: 2 | Batch_idx: 300 |  Loss: (0.0659) | Acc: (97.86%) (11782/12040)\n",
      "Epoch: 2 | Batch_idx: 310 |  Loss: (0.0652) | Acc: (97.89%) (12177/12440)\n",
      "Epoch: 2 | Batch_idx: 320 |  Loss: (0.0645) | Acc: (97.91%) (12572/12840)\n",
      "Epoch: 2 | Batch_idx: 330 |  Loss: (0.0651) | Acc: (97.89%) (12961/13240)\n",
      "Epoch: 2 | Batch_idx: 340 |  Loss: (0.0652) | Acc: (97.90%) (13353/13640)\n",
      "Epoch: 2 | Batch_idx: 350 |  Loss: (0.0645) | Acc: (97.91%) (13747/14040)\n",
      "Epoch: 2 | Batch_idx: 360 |  Loss: (0.0647) | Acc: (97.93%) (14141/14440)\n",
      "Epoch: 2 | Batch_idx: 370 |  Loss: (0.0649) | Acc: (97.90%) (14529/14840)\n",
      "Epoch: 2 | Batch_idx: 380 |  Loss: (0.0658) | Acc: (97.87%) (14915/15240)\n",
      "Epoch: 2 | Batch_idx: 390 |  Loss: (0.0662) | Acc: (97.86%) (15306/15640)\n",
      "Epoch: 2 | Batch_idx: 400 |  Loss: (0.0660) | Acc: (97.87%) (15698/16040)\n",
      "Epoch: 2 | Batch_idx: 410 |  Loss: (0.0660) | Acc: (97.86%) (16089/16440)\n",
      "Epoch: 2 | Batch_idx: 420 |  Loss: (0.0657) | Acc: (97.89%) (16484/16840)\n",
      "Epoch: 2 | Batch_idx: 430 |  Loss: (0.0658) | Acc: (97.87%) (16873/17240)\n",
      "Epoch: 2 | Batch_idx: 440 |  Loss: (0.0651) | Acc: (97.89%) (17268/17640)\n",
      "Epoch: 2 | Batch_idx: 450 |  Loss: (0.0648) | Acc: (97.90%) (17662/18040)\n",
      "Epoch: 2 | Batch_idx: 460 |  Loss: (0.0647) | Acc: (97.89%) (18051/18440)\n",
      "Epoch: 2 | Batch_idx: 470 |  Loss: (0.0640) | Acc: (97.91%) (18446/18840)\n",
      "Epoch: 2 | Batch_idx: 480 |  Loss: (0.0640) | Acc: (97.91%) (18837/19240)\n",
      "Epoch: 2 | Batch_idx: 490 |  Loss: (0.0643) | Acc: (97.90%) (19228/19640)\n",
      "Epoch: 2 | Batch_idx: 500 |  Loss: (0.0643) | Acc: (97.89%) (19618/20040)\n",
      "Epoch: 2 | Batch_idx: 510 |  Loss: (0.0641) | Acc: (97.90%) (20010/20440)\n",
      "Epoch: 2 | Batch_idx: 520 |  Loss: (0.0637) | Acc: (97.92%) (20406/20840)\n",
      "Epoch: 2 | Batch_idx: 530 |  Loss: (0.0635) | Acc: (97.92%) (20798/21240)\n",
      "Epoch: 2 | Batch_idx: 540 |  Loss: (0.0639) | Acc: (97.90%) (21186/21640)\n",
      "Epoch: 2 | Batch_idx: 550 |  Loss: (0.0644) | Acc: (97.88%) (21573/22040)\n",
      "Epoch: 2 | Batch_idx: 560 |  Loss: (0.0646) | Acc: (97.86%) (21960/22440)\n",
      "Epoch: 2 | Batch_idx: 570 |  Loss: (0.0643) | Acc: (97.86%) (22352/22840)\n",
      "Epoch: 2 | Batch_idx: 580 |  Loss: (0.0643) | Acc: (97.86%) (22743/23240)\n",
      "Epoch: 2 | Batch_idx: 590 |  Loss: (0.0639) | Acc: (97.88%) (23139/23640)\n",
      "Epoch: 2 | Batch_idx: 600 |  Loss: (0.0636) | Acc: (97.88%) (23531/24040)\n",
      "Epoch: 2 | Batch_idx: 610 |  Loss: (0.0635) | Acc: (97.91%) (23928/24440)\n",
      "Epoch: 2 | Batch_idx: 620 |  Loss: (0.0636) | Acc: (97.91%) (24320/24840)\n",
      "Epoch: 2 | Batch_idx: 630 |  Loss: (0.0639) | Acc: (97.91%) (24713/25240)\n",
      "Epoch: 2 | Batch_idx: 640 |  Loss: (0.0641) | Acc: (97.91%) (25104/25640)\n",
      "Epoch: 2 | Batch_idx: 650 |  Loss: (0.0643) | Acc: (97.90%) (25492/26040)\n",
      "Epoch: 2 | Batch_idx: 660 |  Loss: (0.0645) | Acc: (97.88%) (25880/26440)\n",
      "Epoch: 2 | Batch_idx: 670 |  Loss: (0.0650) | Acc: (97.87%) (26268/26840)\n",
      "Epoch: 2 | Batch_idx: 680 |  Loss: (0.0655) | Acc: (97.85%) (26654/27240)\n",
      "Epoch: 2 | Batch_idx: 690 |  Loss: (0.0657) | Acc: (97.84%) (27044/27640)\n",
      "Epoch: 2 | Batch_idx: 700 |  Loss: (0.0661) | Acc: (97.83%) (27431/28040)\n",
      "Epoch: 2 | Batch_idx: 710 |  Loss: (0.0656) | Acc: (97.85%) (27829/28440)\n",
      "Epoch: 2 | Batch_idx: 720 |  Loss: (0.0657) | Acc: (97.84%) (28218/28840)\n",
      "Epoch: 2 | Batch_idx: 730 |  Loss: (0.0657) | Acc: (97.84%) (28608/29240)\n",
      "Epoch: 2 | Batch_idx: 740 |  Loss: (0.0659) | Acc: (97.83%) (28996/29640)\n",
      "Epoch: 2 | Batch_idx: 750 |  Loss: (0.0657) | Acc: (97.83%) (29388/30040)\n",
      "Epoch: 2 | Batch_idx: 760 |  Loss: (0.0662) | Acc: (97.83%) (29779/30440)\n",
      "Epoch: 2 | Batch_idx: 770 |  Loss: (0.0662) | Acc: (97.83%) (30170/30840)\n",
      "Epoch: 2 | Batch_idx: 780 |  Loss: (0.0666) | Acc: (97.81%) (30556/31240)\n",
      "Epoch: 2 | Batch_idx: 790 |  Loss: (0.0666) | Acc: (97.81%) (30946/31640)\n",
      "Epoch: 2 | Batch_idx: 800 |  Loss: (0.0664) | Acc: (97.82%) (31341/32040)\n",
      "Epoch: 2 | Batch_idx: 810 |  Loss: (0.0664) | Acc: (97.82%) (31734/32440)\n",
      "Epoch: 2 | Batch_idx: 820 |  Loss: (0.0662) | Acc: (97.83%) (32126/32840)\n",
      "Epoch: 2 | Batch_idx: 830 |  Loss: (0.0661) | Acc: (97.83%) (32519/33240)\n",
      "Epoch: 2 | Batch_idx: 840 |  Loss: (0.0661) | Acc: (97.83%) (32910/33640)\n",
      "Epoch: 2 | Batch_idx: 850 |  Loss: (0.0660) | Acc: (97.83%) (33301/34040)\n",
      "Epoch: 2 | Batch_idx: 860 |  Loss: (0.0660) | Acc: (97.82%) (33690/34440)\n",
      "Epoch: 2 | Batch_idx: 870 |  Loss: (0.0656) | Acc: (97.84%) (34088/34840)\n",
      "Epoch: 2 | Batch_idx: 880 |  Loss: (0.0653) | Acc: (97.85%) (34484/35240)\n",
      "Epoch: 2 | Batch_idx: 890 |  Loss: (0.0654) | Acc: (97.85%) (34872/35640)\n",
      "Epoch: 2 | Batch_idx: 900 |  Loss: (0.0652) | Acc: (97.85%) (35265/36040)\n",
      "Epoch: 2 | Batch_idx: 910 |  Loss: (0.0650) | Acc: (97.86%) (35659/36440)\n",
      "Epoch: 2 | Batch_idx: 920 |  Loss: (0.0646) | Acc: (97.87%) (36056/36840)\n",
      "Epoch: 2 | Batch_idx: 930 |  Loss: (0.0644) | Acc: (97.88%) (36449/37240)\n",
      "Epoch: 2 | Batch_idx: 940 |  Loss: (0.0643) | Acc: (97.88%) (36842/37640)\n",
      "Epoch: 2 | Batch_idx: 950 |  Loss: (0.0638) | Acc: (97.90%) (37242/38040)\n",
      "Epoch: 2 | Batch_idx: 960 |  Loss: (0.0637) | Acc: (97.90%) (37634/38440)\n",
      "Epoch: 2 | Batch_idx: 970 |  Loss: (0.0640) | Acc: (97.90%) (38026/38840)\n",
      "Epoch: 2 | Batch_idx: 980 |  Loss: (0.0642) | Acc: (97.90%) (38415/39240)\n",
      "Epoch: 2 | Batch_idx: 990 |  Loss: (0.0643) | Acc: (97.89%) (38805/39640)\n",
      "Epoch: 2 | Batch_idx: 1000 |  Loss: (0.0642) | Acc: (97.90%) (39200/40040)\n",
      "Epoch: 2 | Batch_idx: 1010 |  Loss: (0.0642) | Acc: (97.91%) (39594/40440)\n",
      "Epoch: 2 | Batch_idx: 1020 |  Loss: (0.0639) | Acc: (97.92%) (39989/40840)\n",
      "Epoch: 2 | Batch_idx: 1030 |  Loss: (0.0642) | Acc: (97.90%) (40376/41240)\n",
      "Epoch: 2 | Batch_idx: 1040 |  Loss: (0.0644) | Acc: (97.89%) (40763/41640)\n",
      "Epoch: 2 | Batch_idx: 1050 |  Loss: (0.0641) | Acc: (97.90%) (41159/42040)\n",
      "Epoch: 2 | Batch_idx: 1060 |  Loss: (0.0640) | Acc: (97.91%) (41551/42440)\n",
      "Epoch: 2 | Batch_idx: 1070 |  Loss: (0.0639) | Acc: (97.91%) (41944/42840)\n",
      "Epoch: 2 | Batch_idx: 1080 |  Loss: (0.0636) | Acc: (97.91%) (42338/43240)\n",
      "Epoch: 2 | Batch_idx: 1090 |  Loss: (0.0635) | Acc: (97.92%) (42734/43640)\n",
      "Epoch: 2 | Batch_idx: 1100 |  Loss: (0.0637) | Acc: (97.91%) (43119/44040)\n",
      "Epoch: 2 | Batch_idx: 1110 |  Loss: (0.0638) | Acc: (97.91%) (43509/44440)\n",
      "Epoch: 2 | Batch_idx: 1120 |  Loss: (0.0642) | Acc: (97.90%) (43898/44840)\n",
      "Epoch: 2 | Batch_idx: 1130 |  Loss: (0.0640) | Acc: (97.91%) (44293/45240)\n",
      "Epoch: 2 | Batch_idx: 1140 |  Loss: (0.0638) | Acc: (97.91%) (44687/45640)\n",
      "Epoch: 2 | Batch_idx: 1150 |  Loss: (0.0639) | Acc: (97.91%) (45080/46040)\n",
      "Epoch: 2 | Batch_idx: 1160 |  Loss: (0.0638) | Acc: (97.92%) (45474/46440)\n",
      "Epoch: 2 | Batch_idx: 1170 |  Loss: (0.0640) | Acc: (97.91%) (45859/46840)\n",
      "Epoch: 2 | Batch_idx: 1180 |  Loss: (0.0639) | Acc: (97.91%) (46252/47240)\n",
      "Epoch: 2 | Batch_idx: 1190 |  Loss: (0.0640) | Acc: (97.91%) (46643/47640)\n",
      "Epoch: 2 | Batch_idx: 1200 |  Loss: (0.0641) | Acc: (97.90%) (47032/48040)\n",
      "Epoch: 2 | Batch_idx: 1210 |  Loss: (0.0638) | Acc: (97.91%) (47428/48440)\n",
      "Epoch: 2 | Batch_idx: 1220 |  Loss: (0.0640) | Acc: (97.91%) (47819/48840)\n",
      "Epoch: 2 | Batch_idx: 1230 |  Loss: (0.0639) | Acc: (97.92%) (48214/49240)\n",
      "Epoch: 2 | Batch_idx: 1240 |  Loss: (0.0636) | Acc: (97.92%) (48609/49640)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.1616) | Acc: (95.13%) (9513/10000)\n",
      "Epoch: 3 | Batch_idx: 0 |  Loss: (0.0726) | Acc: (97.50%) (39/40)\n",
      "Epoch: 3 | Batch_idx: 10 |  Loss: (0.0414) | Acc: (97.95%) (431/440)\n",
      "Epoch: 3 | Batch_idx: 20 |  Loss: (0.0388) | Acc: (98.21%) (825/840)\n",
      "Epoch: 3 | Batch_idx: 30 |  Loss: (0.0410) | Acc: (98.23%) (1218/1240)\n",
      "Epoch: 3 | Batch_idx: 40 |  Loss: (0.0387) | Acc: (98.29%) (1612/1640)\n",
      "Epoch: 3 | Batch_idx: 50 |  Loss: (0.0407) | Acc: (98.33%) (2006/2040)\n",
      "Epoch: 3 | Batch_idx: 60 |  Loss: (0.0380) | Acc: (98.52%) (2404/2440)\n",
      "Epoch: 3 | Batch_idx: 70 |  Loss: (0.0430) | Acc: (98.38%) (2794/2840)\n",
      "Epoch: 3 | Batch_idx: 80 |  Loss: (0.0428) | Acc: (98.43%) (3189/3240)\n",
      "Epoch: 3 | Batch_idx: 90 |  Loss: (0.0427) | Acc: (98.43%) (3583/3640)\n",
      "Epoch: 3 | Batch_idx: 100 |  Loss: (0.0432) | Acc: (98.44%) (3977/4040)\n",
      "Epoch: 3 | Batch_idx: 110 |  Loss: (0.0433) | Acc: (98.40%) (4369/4440)\n",
      "Epoch: 3 | Batch_idx: 120 |  Loss: (0.0431) | Acc: (98.43%) (4764/4840)\n",
      "Epoch: 3 | Batch_idx: 130 |  Loss: (0.0418) | Acc: (98.47%) (5160/5240)\n",
      "Epoch: 3 | Batch_idx: 140 |  Loss: (0.0424) | Acc: (98.51%) (5556/5640)\n",
      "Epoch: 3 | Batch_idx: 150 |  Loss: (0.0418) | Acc: (98.56%) (5953/6040)\n",
      "Epoch: 3 | Batch_idx: 160 |  Loss: (0.0434) | Acc: (98.54%) (6346/6440)\n",
      "Epoch: 3 | Batch_idx: 170 |  Loss: (0.0435) | Acc: (98.54%) (6740/6840)\n",
      "Epoch: 3 | Batch_idx: 180 |  Loss: (0.0432) | Acc: (98.56%) (7136/7240)\n",
      "Epoch: 3 | Batch_idx: 190 |  Loss: (0.0431) | Acc: (98.55%) (7529/7640)\n",
      "Epoch: 3 | Batch_idx: 200 |  Loss: (0.0421) | Acc: (98.58%) (7926/8040)\n",
      "Epoch: 3 | Batch_idx: 210 |  Loss: (0.0419) | Acc: (98.59%) (8321/8440)\n",
      "Epoch: 3 | Batch_idx: 220 |  Loss: (0.0427) | Acc: (98.51%) (8708/8840)\n",
      "Epoch: 3 | Batch_idx: 230 |  Loss: (0.0426) | Acc: (98.54%) (9105/9240)\n",
      "Epoch: 3 | Batch_idx: 240 |  Loss: (0.0426) | Acc: (98.55%) (9500/9640)\n",
      "Epoch: 3 | Batch_idx: 250 |  Loss: (0.0422) | Acc: (98.55%) (9894/10040)\n",
      "Epoch: 3 | Batch_idx: 260 |  Loss: (0.0422) | Acc: (98.54%) (10288/10440)\n",
      "Epoch: 3 | Batch_idx: 270 |  Loss: (0.0429) | Acc: (98.54%) (10682/10840)\n",
      "Epoch: 3 | Batch_idx: 280 |  Loss: (0.0426) | Acc: (98.53%) (11075/11240)\n",
      "Epoch: 3 | Batch_idx: 290 |  Loss: (0.0424) | Acc: (98.53%) (11469/11640)\n",
      "Epoch: 3 | Batch_idx: 300 |  Loss: (0.0419) | Acc: (98.55%) (11865/12040)\n",
      "Epoch: 3 | Batch_idx: 310 |  Loss: (0.0417) | Acc: (98.57%) (12262/12440)\n",
      "Epoch: 3 | Batch_idx: 320 |  Loss: (0.0417) | Acc: (98.57%) (12657/12840)\n",
      "Epoch: 3 | Batch_idx: 330 |  Loss: (0.0408) | Acc: (98.62%) (13057/13240)\n",
      "Epoch: 3 | Batch_idx: 340 |  Loss: (0.0406) | Acc: (98.62%) (13452/13640)\n",
      "Epoch: 3 | Batch_idx: 350 |  Loss: (0.0409) | Acc: (98.61%) (13845/14040)\n",
      "Epoch: 3 | Batch_idx: 360 |  Loss: (0.0404) | Acc: (98.63%) (14242/14440)\n",
      "Epoch: 3 | Batch_idx: 370 |  Loss: (0.0398) | Acc: (98.65%) (14640/14840)\n",
      "Epoch: 3 | Batch_idx: 380 |  Loss: (0.0393) | Acc: (98.65%) (15035/15240)\n",
      "Epoch: 3 | Batch_idx: 390 |  Loss: (0.0395) | Acc: (98.64%) (15427/15640)\n",
      "Epoch: 3 | Batch_idx: 400 |  Loss: (0.0394) | Acc: (98.63%) (15820/16040)\n",
      "Epoch: 3 | Batch_idx: 410 |  Loss: (0.0400) | Acc: (98.61%) (16212/16440)\n",
      "Epoch: 3 | Batch_idx: 420 |  Loss: (0.0406) | Acc: (98.59%) (16602/16840)\n",
      "Epoch: 3 | Batch_idx: 430 |  Loss: (0.0404) | Acc: (98.60%) (16998/17240)\n",
      "Epoch: 3 | Batch_idx: 440 |  Loss: (0.0403) | Acc: (98.60%) (17393/17640)\n",
      "Epoch: 3 | Batch_idx: 450 |  Loss: (0.0404) | Acc: (98.60%) (17788/18040)\n",
      "Epoch: 3 | Batch_idx: 460 |  Loss: (0.0403) | Acc: (98.59%) (18180/18440)\n",
      "Epoch: 3 | Batch_idx: 470 |  Loss: (0.0402) | Acc: (98.59%) (18574/18840)\n",
      "Epoch: 3 | Batch_idx: 480 |  Loss: (0.0402) | Acc: (98.59%) (18969/19240)\n",
      "Epoch: 3 | Batch_idx: 490 |  Loss: (0.0399) | Acc: (98.60%) (19365/19640)\n",
      "Epoch: 3 | Batch_idx: 500 |  Loss: (0.0407) | Acc: (98.58%) (19755/20040)\n",
      "Epoch: 3 | Batch_idx: 510 |  Loss: (0.0405) | Acc: (98.59%) (20152/20440)\n",
      "Epoch: 3 | Batch_idx: 520 |  Loss: (0.0403) | Acc: (98.60%) (20548/20840)\n",
      "Epoch: 3 | Batch_idx: 530 |  Loss: (0.0407) | Acc: (98.59%) (20941/21240)\n",
      "Epoch: 3 | Batch_idx: 540 |  Loss: (0.0412) | Acc: (98.59%) (21335/21640)\n",
      "Epoch: 3 | Batch_idx: 550 |  Loss: (0.0410) | Acc: (98.60%) (21731/22040)\n",
      "Epoch: 3 | Batch_idx: 560 |  Loss: (0.0409) | Acc: (98.60%) (22125/22440)\n",
      "Epoch: 3 | Batch_idx: 570 |  Loss: (0.0412) | Acc: (98.59%) (22519/22840)\n",
      "Epoch: 3 | Batch_idx: 580 |  Loss: (0.0412) | Acc: (98.59%) (22913/23240)\n",
      "Epoch: 3 | Batch_idx: 590 |  Loss: (0.0410) | Acc: (98.60%) (23310/23640)\n",
      "Epoch: 3 | Batch_idx: 600 |  Loss: (0.0408) | Acc: (98.60%) (23703/24040)\n",
      "Epoch: 3 | Batch_idx: 610 |  Loss: (0.0408) | Acc: (98.60%) (24098/24440)\n",
      "Epoch: 3 | Batch_idx: 620 |  Loss: (0.0409) | Acc: (98.60%) (24493/24840)\n",
      "Epoch: 3 | Batch_idx: 630 |  Loss: (0.0409) | Acc: (98.61%) (24888/25240)\n",
      "Epoch: 3 | Batch_idx: 640 |  Loss: (0.0411) | Acc: (98.60%) (25282/25640)\n",
      "Epoch: 3 | Batch_idx: 650 |  Loss: (0.0411) | Acc: (98.61%) (25677/26040)\n",
      "Epoch: 3 | Batch_idx: 660 |  Loss: (0.0417) | Acc: (98.59%) (26068/26440)\n",
      "Epoch: 3 | Batch_idx: 670 |  Loss: (0.0416) | Acc: (98.60%) (26465/26840)\n",
      "Epoch: 3 | Batch_idx: 680 |  Loss: (0.0417) | Acc: (98.60%) (26858/27240)\n",
      "Epoch: 3 | Batch_idx: 690 |  Loss: (0.0417) | Acc: (98.60%) (27253/27640)\n",
      "Epoch: 3 | Batch_idx: 700 |  Loss: (0.0421) | Acc: (98.58%) (27642/28040)\n",
      "Epoch: 3 | Batch_idx: 710 |  Loss: (0.0421) | Acc: (98.59%) (28038/28440)\n",
      "Epoch: 3 | Batch_idx: 720 |  Loss: (0.0423) | Acc: (98.58%) (28431/28840)\n",
      "Epoch: 3 | Batch_idx: 730 |  Loss: (0.0422) | Acc: (98.59%) (28827/29240)\n",
      "Epoch: 3 | Batch_idx: 740 |  Loss: (0.0422) | Acc: (98.59%) (29222/29640)\n",
      "Epoch: 3 | Batch_idx: 750 |  Loss: (0.0419) | Acc: (98.60%) (29619/30040)\n",
      "Epoch: 3 | Batch_idx: 760 |  Loss: (0.0420) | Acc: (98.59%) (30012/30440)\n",
      "Epoch: 3 | Batch_idx: 770 |  Loss: (0.0419) | Acc: (98.61%) (30410/30840)\n",
      "Epoch: 3 | Batch_idx: 780 |  Loss: (0.0418) | Acc: (98.62%) (30808/31240)\n",
      "Epoch: 3 | Batch_idx: 790 |  Loss: (0.0418) | Acc: (98.62%) (31204/31640)\n",
      "Epoch: 3 | Batch_idx: 800 |  Loss: (0.0417) | Acc: (98.63%) (31602/32040)\n",
      "Epoch: 3 | Batch_idx: 810 |  Loss: (0.0414) | Acc: (98.64%) (32000/32440)\n",
      "Epoch: 3 | Batch_idx: 820 |  Loss: (0.0413) | Acc: (98.64%) (32395/32840)\n",
      "Epoch: 3 | Batch_idx: 830 |  Loss: (0.0412) | Acc: (98.64%) (32789/33240)\n",
      "Epoch: 3 | Batch_idx: 840 |  Loss: (0.0409) | Acc: (98.65%) (33186/33640)\n",
      "Epoch: 3 | Batch_idx: 850 |  Loss: (0.0410) | Acc: (98.65%) (33581/34040)\n",
      "Epoch: 3 | Batch_idx: 860 |  Loss: (0.0410) | Acc: (98.65%) (33975/34440)\n",
      "Epoch: 3 | Batch_idx: 870 |  Loss: (0.0409) | Acc: (98.65%) (34368/34840)\n",
      "Epoch: 3 | Batch_idx: 880 |  Loss: (0.0410) | Acc: (98.65%) (34764/35240)\n",
      "Epoch: 3 | Batch_idx: 890 |  Loss: (0.0412) | Acc: (98.65%) (35159/35640)\n",
      "Epoch: 3 | Batch_idx: 900 |  Loss: (0.0410) | Acc: (98.65%) (35555/36040)\n",
      "Epoch: 3 | Batch_idx: 910 |  Loss: (0.0411) | Acc: (98.66%) (35952/36440)\n",
      "Epoch: 3 | Batch_idx: 920 |  Loss: (0.0410) | Acc: (98.66%) (36345/36840)\n",
      "Epoch: 3 | Batch_idx: 930 |  Loss: (0.0410) | Acc: (98.65%) (36739/37240)\n",
      "Epoch: 3 | Batch_idx: 940 |  Loss: (0.0409) | Acc: (98.66%) (37135/37640)\n",
      "Epoch: 3 | Batch_idx: 950 |  Loss: (0.0409) | Acc: (98.66%) (37531/38040)\n",
      "Epoch: 3 | Batch_idx: 960 |  Loss: (0.0408) | Acc: (98.67%) (37928/38440)\n",
      "Epoch: 3 | Batch_idx: 970 |  Loss: (0.0407) | Acc: (98.67%) (38324/38840)\n",
      "Epoch: 3 | Batch_idx: 980 |  Loss: (0.0404) | Acc: (98.68%) (38722/39240)\n",
      "Epoch: 3 | Batch_idx: 990 |  Loss: (0.0402) | Acc: (98.69%) (39119/39640)\n",
      "Epoch: 3 | Batch_idx: 1000 |  Loss: (0.0401) | Acc: (98.69%) (39517/40040)\n",
      "Epoch: 3 | Batch_idx: 1010 |  Loss: (0.0401) | Acc: (98.69%) (39911/40440)\n",
      "Epoch: 3 | Batch_idx: 1020 |  Loss: (0.0402) | Acc: (98.70%) (40308/40840)\n",
      "Epoch: 3 | Batch_idx: 1030 |  Loss: (0.0402) | Acc: (98.70%) (40705/41240)\n",
      "Epoch: 3 | Batch_idx: 1040 |  Loss: (0.0405) | Acc: (98.69%) (41096/41640)\n",
      "Epoch: 3 | Batch_idx: 1050 |  Loss: (0.0406) | Acc: (98.70%) (41492/42040)\n",
      "Epoch: 3 | Batch_idx: 1060 |  Loss: (0.0406) | Acc: (98.69%) (41886/42440)\n",
      "Epoch: 3 | Batch_idx: 1070 |  Loss: (0.0406) | Acc: (98.70%) (42281/42840)\n",
      "Epoch: 3 | Batch_idx: 1080 |  Loss: (0.0408) | Acc: (98.69%) (42673/43240)\n",
      "Epoch: 3 | Batch_idx: 1090 |  Loss: (0.0412) | Acc: (98.68%) (43062/43640)\n",
      "Epoch: 3 | Batch_idx: 1100 |  Loss: (0.0411) | Acc: (98.68%) (43459/44040)\n",
      "Epoch: 3 | Batch_idx: 1110 |  Loss: (0.0410) | Acc: (98.68%) (43854/44440)\n",
      "Epoch: 3 | Batch_idx: 1120 |  Loss: (0.0410) | Acc: (98.68%) (44250/44840)\n",
      "Epoch: 3 | Batch_idx: 1130 |  Loss: (0.0410) | Acc: (98.68%) (44644/45240)\n",
      "Epoch: 3 | Batch_idx: 1140 |  Loss: (0.0413) | Acc: (98.67%) (45035/45640)\n",
      "Epoch: 3 | Batch_idx: 1150 |  Loss: (0.0412) | Acc: (98.68%) (45430/46040)\n",
      "Epoch: 3 | Batch_idx: 1160 |  Loss: (0.0409) | Acc: (98.68%) (45828/46440)\n",
      "Epoch: 3 | Batch_idx: 1170 |  Loss: (0.0411) | Acc: (98.68%) (46220/46840)\n",
      "Epoch: 3 | Batch_idx: 1180 |  Loss: (0.0411) | Acc: (98.67%) (46613/47240)\n",
      "Epoch: 3 | Batch_idx: 1190 |  Loss: (0.0410) | Acc: (98.68%) (47009/47640)\n",
      "Epoch: 3 | Batch_idx: 1200 |  Loss: (0.0410) | Acc: (98.68%) (47405/48040)\n",
      "Epoch: 3 | Batch_idx: 1210 |  Loss: (0.0410) | Acc: (98.67%) (47797/48440)\n",
      "Epoch: 3 | Batch_idx: 1220 |  Loss: (0.0409) | Acc: (98.68%) (48194/48840)\n",
      "Epoch: 3 | Batch_idx: 1230 |  Loss: (0.0411) | Acc: (98.67%) (48587/49240)\n",
      "Epoch: 3 | Batch_idx: 1240 |  Loss: (0.0411) | Acc: (98.67%) (48981/49640)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.1550) | Acc: (95.43%) (9543/10000)\n",
      "Epoch: 4 | Batch_idx: 0 |  Loss: (0.0234) | Acc: (97.50%) (39/40)\n",
      "Epoch: 4 | Batch_idx: 10 |  Loss: (0.0300) | Acc: (98.86%) (435/440)\n",
      "Epoch: 4 | Batch_idx: 20 |  Loss: (0.0216) | Acc: (99.29%) (834/840)\n",
      "Epoch: 4 | Batch_idx: 30 |  Loss: (0.0289) | Acc: (99.11%) (1229/1240)\n",
      "Epoch: 4 | Batch_idx: 40 |  Loss: (0.0290) | Acc: (99.15%) (1626/1640)\n",
      "Epoch: 4 | Batch_idx: 50 |  Loss: (0.0272) | Acc: (99.26%) (2025/2040)\n",
      "Epoch: 4 | Batch_idx: 60 |  Loss: (0.0243) | Acc: (99.34%) (2424/2440)\n",
      "Epoch: 4 | Batch_idx: 70 |  Loss: (0.0239) | Acc: (99.30%) (2820/2840)\n",
      "Epoch: 4 | Batch_idx: 80 |  Loss: (0.0232) | Acc: (99.32%) (3218/3240)\n",
      "Epoch: 4 | Batch_idx: 90 |  Loss: (0.0234) | Acc: (99.31%) (3615/3640)\n",
      "Epoch: 4 | Batch_idx: 100 |  Loss: (0.0217) | Acc: (99.38%) (4015/4040)\n",
      "Epoch: 4 | Batch_idx: 110 |  Loss: (0.0221) | Acc: (99.39%) (4413/4440)\n",
      "Epoch: 4 | Batch_idx: 120 |  Loss: (0.0216) | Acc: (99.40%) (4811/4840)\n",
      "Epoch: 4 | Batch_idx: 130 |  Loss: (0.0211) | Acc: (99.43%) (5210/5240)\n",
      "Epoch: 4 | Batch_idx: 140 |  Loss: (0.0206) | Acc: (99.43%) (5608/5640)\n",
      "Epoch: 4 | Batch_idx: 150 |  Loss: (0.0224) | Acc: (99.40%) (6004/6040)\n",
      "Epoch: 4 | Batch_idx: 160 |  Loss: (0.0219) | Acc: (99.43%) (6403/6440)\n",
      "Epoch: 4 | Batch_idx: 170 |  Loss: (0.0216) | Acc: (99.42%) (6800/6840)\n",
      "Epoch: 4 | Batch_idx: 180 |  Loss: (0.0212) | Acc: (99.43%) (7199/7240)\n",
      "Epoch: 4 | Batch_idx: 190 |  Loss: (0.0212) | Acc: (99.41%) (7595/7640)\n",
      "Epoch: 4 | Batch_idx: 200 |  Loss: (0.0209) | Acc: (99.42%) (7993/8040)\n",
      "Epoch: 4 | Batch_idx: 210 |  Loss: (0.0208) | Acc: (99.41%) (8390/8440)\n",
      "Epoch: 4 | Batch_idx: 220 |  Loss: (0.0202) | Acc: (99.43%) (8790/8840)\n",
      "Epoch: 4 | Batch_idx: 230 |  Loss: (0.0200) | Acc: (99.43%) (9187/9240)\n",
      "Epoch: 4 | Batch_idx: 240 |  Loss: (0.0198) | Acc: (99.43%) (9585/9640)\n",
      "Epoch: 4 | Batch_idx: 250 |  Loss: (0.0200) | Acc: (99.42%) (9982/10040)\n",
      "Epoch: 4 | Batch_idx: 260 |  Loss: (0.0201) | Acc: (99.42%) (10379/10440)\n",
      "Epoch: 4 | Batch_idx: 270 |  Loss: (0.0203) | Acc: (99.40%) (10775/10840)\n",
      "Epoch: 4 | Batch_idx: 280 |  Loss: (0.0202) | Acc: (99.40%) (11172/11240)\n",
      "Epoch: 4 | Batch_idx: 290 |  Loss: (0.0199) | Acc: (99.40%) (11570/11640)\n",
      "Epoch: 4 | Batch_idx: 300 |  Loss: (0.0201) | Acc: (99.41%) (11969/12040)\n",
      "Epoch: 4 | Batch_idx: 310 |  Loss: (0.0199) | Acc: (99.42%) (12368/12440)\n",
      "Epoch: 4 | Batch_idx: 320 |  Loss: (0.0197) | Acc: (99.42%) (12766/12840)\n",
      "Epoch: 4 | Batch_idx: 330 |  Loss: (0.0198) | Acc: (99.42%) (13163/13240)\n",
      "Epoch: 4 | Batch_idx: 340 |  Loss: (0.0195) | Acc: (99.43%) (13562/13640)\n",
      "Epoch: 4 | Batch_idx: 350 |  Loss: (0.0194) | Acc: (99.42%) (13958/14040)\n",
      "Epoch: 4 | Batch_idx: 360 |  Loss: (0.0194) | Acc: (99.43%) (14357/14440)\n",
      "Epoch: 4 | Batch_idx: 370 |  Loss: (0.0189) | Acc: (99.44%) (14757/14840)\n",
      "Epoch: 4 | Batch_idx: 380 |  Loss: (0.0190) | Acc: (99.44%) (15154/15240)\n",
      "Epoch: 4 | Batch_idx: 390 |  Loss: (0.0198) | Acc: (99.41%) (15548/15640)\n",
      "Epoch: 4 | Batch_idx: 400 |  Loss: (0.0199) | Acc: (99.40%) (15944/16040)\n",
      "Epoch: 4 | Batch_idx: 410 |  Loss: (0.0205) | Acc: (99.39%) (16339/16440)\n",
      "Epoch: 4 | Batch_idx: 420 |  Loss: (0.0205) | Acc: (99.38%) (16736/16840)\n",
      "Epoch: 4 | Batch_idx: 430 |  Loss: (0.0203) | Acc: (99.38%) (17133/17240)\n",
      "Epoch: 4 | Batch_idx: 440 |  Loss: (0.0203) | Acc: (99.38%) (17530/17640)\n",
      "Epoch: 4 | Batch_idx: 450 |  Loss: (0.0203) | Acc: (99.37%) (17927/18040)\n",
      "Epoch: 4 | Batch_idx: 460 |  Loss: (0.0206) | Acc: (99.37%) (18323/18440)\n",
      "Epoch: 4 | Batch_idx: 470 |  Loss: (0.0210) | Acc: (99.35%) (18717/18840)\n",
      "Epoch: 4 | Batch_idx: 480 |  Loss: (0.0211) | Acc: (99.35%) (19114/19240)\n",
      "Epoch: 4 | Batch_idx: 490 |  Loss: (0.0214) | Acc: (99.33%) (19508/19640)\n",
      "Epoch: 4 | Batch_idx: 500 |  Loss: (0.0214) | Acc: (99.33%) (19905/20040)\n",
      "Epoch: 4 | Batch_idx: 510 |  Loss: (0.0214) | Acc: (99.33%) (20303/20440)\n",
      "Epoch: 4 | Batch_idx: 520 |  Loss: (0.0219) | Acc: (99.31%) (20697/20840)\n",
      "Epoch: 4 | Batch_idx: 530 |  Loss: (0.0216) | Acc: (99.32%) (21096/21240)\n",
      "Epoch: 4 | Batch_idx: 540 |  Loss: (0.0217) | Acc: (99.32%) (21493/21640)\n",
      "Epoch: 4 | Batch_idx: 550 |  Loss: (0.0215) | Acc: (99.33%) (21892/22040)\n",
      "Epoch: 4 | Batch_idx: 560 |  Loss: (0.0214) | Acc: (99.34%) (22291/22440)\n",
      "Epoch: 4 | Batch_idx: 570 |  Loss: (0.0214) | Acc: (99.34%) (22689/22840)\n",
      "Epoch: 4 | Batch_idx: 580 |  Loss: (0.0218) | Acc: (99.33%) (23084/23240)\n",
      "Epoch: 4 | Batch_idx: 590 |  Loss: (0.0217) | Acc: (99.33%) (23482/23640)\n",
      "Epoch: 4 | Batch_idx: 600 |  Loss: (0.0220) | Acc: (99.32%) (23876/24040)\n",
      "Epoch: 4 | Batch_idx: 610 |  Loss: (0.0220) | Acc: (99.32%) (24274/24440)\n",
      "Epoch: 4 | Batch_idx: 620 |  Loss: (0.0220) | Acc: (99.32%) (24671/24840)\n",
      "Epoch: 4 | Batch_idx: 630 |  Loss: (0.0223) | Acc: (99.30%) (25064/25240)\n",
      "Epoch: 4 | Batch_idx: 640 |  Loss: (0.0225) | Acc: (99.30%) (25460/25640)\n",
      "Epoch: 4 | Batch_idx: 650 |  Loss: (0.0229) | Acc: (99.28%) (25853/26040)\n",
      "Epoch: 4 | Batch_idx: 660 |  Loss: (0.0228) | Acc: (99.28%) (26250/26440)\n",
      "Epoch: 4 | Batch_idx: 670 |  Loss: (0.0228) | Acc: (99.28%) (26646/26840)\n",
      "Epoch: 4 | Batch_idx: 680 |  Loss: (0.0228) | Acc: (99.27%) (27042/27240)\n",
      "Epoch: 4 | Batch_idx: 690 |  Loss: (0.0229) | Acc: (99.27%) (27439/27640)\n",
      "Epoch: 4 | Batch_idx: 700 |  Loss: (0.0227) | Acc: (99.28%) (27838/28040)\n",
      "Epoch: 4 | Batch_idx: 710 |  Loss: (0.0226) | Acc: (99.29%) (28237/28440)\n",
      "Epoch: 4 | Batch_idx: 720 |  Loss: (0.0226) | Acc: (99.29%) (28634/28840)\n",
      "Epoch: 4 | Batch_idx: 730 |  Loss: (0.0225) | Acc: (99.29%) (29031/29240)\n",
      "Epoch: 4 | Batch_idx: 740 |  Loss: (0.0224) | Acc: (99.29%) (29430/29640)\n",
      "Epoch: 4 | Batch_idx: 750 |  Loss: (0.0224) | Acc: (99.28%) (29825/30040)\n",
      "Epoch: 4 | Batch_idx: 760 |  Loss: (0.0228) | Acc: (99.27%) (30218/30440)\n",
      "Epoch: 4 | Batch_idx: 770 |  Loss: (0.0229) | Acc: (99.27%) (30615/30840)\n",
      "Epoch: 4 | Batch_idx: 780 |  Loss: (0.0229) | Acc: (99.27%) (31012/31240)\n",
      "Epoch: 4 | Batch_idx: 790 |  Loss: (0.0231) | Acc: (99.26%) (31405/31640)\n",
      "Epoch: 4 | Batch_idx: 800 |  Loss: (0.0235) | Acc: (99.24%) (31797/32040)\n",
      "Epoch: 4 | Batch_idx: 810 |  Loss: (0.0234) | Acc: (99.24%) (32194/32440)\n",
      "Epoch: 4 | Batch_idx: 820 |  Loss: (0.0238) | Acc: (99.24%) (32589/32840)\n",
      "Epoch: 4 | Batch_idx: 830 |  Loss: (0.0237) | Acc: (99.24%) (32989/33240)\n",
      "Epoch: 4 | Batch_idx: 840 |  Loss: (0.0235) | Acc: (99.25%) (33389/33640)\n",
      "Epoch: 4 | Batch_idx: 850 |  Loss: (0.0234) | Acc: (99.26%) (33788/34040)\n",
      "Epoch: 4 | Batch_idx: 860 |  Loss: (0.0232) | Acc: (99.27%) (34187/34440)\n",
      "Epoch: 4 | Batch_idx: 870 |  Loss: (0.0231) | Acc: (99.27%) (34585/34840)\n",
      "Epoch: 4 | Batch_idx: 880 |  Loss: (0.0230) | Acc: (99.28%) (34985/35240)\n",
      "Epoch: 4 | Batch_idx: 890 |  Loss: (0.0230) | Acc: (99.28%) (35383/35640)\n",
      "Epoch: 4 | Batch_idx: 900 |  Loss: (0.0230) | Acc: (99.27%) (35778/36040)\n",
      "Epoch: 4 | Batch_idx: 910 |  Loss: (0.0231) | Acc: (99.28%) (36176/36440)\n",
      "Epoch: 4 | Batch_idx: 920 |  Loss: (0.0229) | Acc: (99.28%) (36575/36840)\n",
      "Epoch: 4 | Batch_idx: 930 |  Loss: (0.0229) | Acc: (99.28%) (36972/37240)\n",
      "Epoch: 4 | Batch_idx: 940 |  Loss: (0.0229) | Acc: (99.28%) (37370/37640)\n",
      "Epoch: 4 | Batch_idx: 950 |  Loss: (0.0229) | Acc: (99.28%) (37767/38040)\n",
      "Epoch: 4 | Batch_idx: 960 |  Loss: (0.0228) | Acc: (99.29%) (38167/38440)\n",
      "Epoch: 4 | Batch_idx: 970 |  Loss: (0.0230) | Acc: (99.29%) (38564/38840)\n",
      "Epoch: 4 | Batch_idx: 980 |  Loss: (0.0230) | Acc: (99.29%) (38963/39240)\n",
      "Epoch: 4 | Batch_idx: 990 |  Loss: (0.0232) | Acc: (99.28%) (39355/39640)\n",
      "Epoch: 4 | Batch_idx: 1000 |  Loss: (0.0231) | Acc: (99.29%) (39754/40040)\n",
      "Epoch: 4 | Batch_idx: 1010 |  Loss: (0.0233) | Acc: (99.28%) (40149/40440)\n",
      "Epoch: 4 | Batch_idx: 1020 |  Loss: (0.0233) | Acc: (99.28%) (40547/40840)\n",
      "Epoch: 4 | Batch_idx: 1030 |  Loss: (0.0232) | Acc: (99.28%) (40944/41240)\n",
      "Epoch: 4 | Batch_idx: 1040 |  Loss: (0.0235) | Acc: (99.27%) (41336/41640)\n",
      "Epoch: 4 | Batch_idx: 1050 |  Loss: (0.0234) | Acc: (99.27%) (41735/42040)\n",
      "Epoch: 4 | Batch_idx: 1060 |  Loss: (0.0234) | Acc: (99.27%) (42132/42440)\n",
      "Epoch: 4 | Batch_idx: 1070 |  Loss: (0.0235) | Acc: (99.27%) (42528/42840)\n",
      "Epoch: 4 | Batch_idx: 1080 |  Loss: (0.0234) | Acc: (99.27%) (42926/43240)\n",
      "Epoch: 4 | Batch_idx: 1090 |  Loss: (0.0233) | Acc: (99.28%) (43326/43640)\n",
      "Epoch: 4 | Batch_idx: 1100 |  Loss: (0.0232) | Acc: (99.28%) (43724/44040)\n",
      "Epoch: 4 | Batch_idx: 1110 |  Loss: (0.0234) | Acc: (99.27%) (44117/44440)\n",
      "Epoch: 4 | Batch_idx: 1120 |  Loss: (0.0233) | Acc: (99.27%) (44514/44840)\n",
      "Epoch: 4 | Batch_idx: 1130 |  Loss: (0.0234) | Acc: (99.27%) (44910/45240)\n",
      "Epoch: 4 | Batch_idx: 1140 |  Loss: (0.0234) | Acc: (99.27%) (45307/45640)\n",
      "Epoch: 4 | Batch_idx: 1150 |  Loss: (0.0233) | Acc: (99.27%) (45704/46040)\n",
      "Epoch: 4 | Batch_idx: 1160 |  Loss: (0.0233) | Acc: (99.27%) (46100/46440)\n",
      "Epoch: 4 | Batch_idx: 1170 |  Loss: (0.0233) | Acc: (99.27%) (46497/46840)\n",
      "Epoch: 4 | Batch_idx: 1180 |  Loss: (0.0232) | Acc: (99.27%) (46894/47240)\n",
      "Epoch: 4 | Batch_idx: 1190 |  Loss: (0.0233) | Acc: (99.27%) (47291/47640)\n",
      "Epoch: 4 | Batch_idx: 1200 |  Loss: (0.0233) | Acc: (99.27%) (47688/48040)\n",
      "Epoch: 4 | Batch_idx: 1210 |  Loss: (0.0235) | Acc: (99.26%) (48083/48440)\n",
      "Epoch: 4 | Batch_idx: 1220 |  Loss: (0.0234) | Acc: (99.27%) (48482/48840)\n",
      "Epoch: 4 | Batch_idx: 1230 |  Loss: (0.0234) | Acc: (99.27%) (48879/49240)\n",
      "Epoch: 4 | Batch_idx: 1240 |  Loss: (0.0233) | Acc: (99.27%) (49278/49640)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.1704) | Acc: (95.40%) (9540/10000)\n",
      "Epoch: 5 | Batch_idx: 0 |  Loss: (0.0185) | Acc: (100.00%) (40/40)\n",
      "Epoch: 5 | Batch_idx: 10 |  Loss: (0.0150) | Acc: (99.77%) (439/440)\n",
      "Epoch: 5 | Batch_idx: 20 |  Loss: (0.0259) | Acc: (99.52%) (836/840)\n",
      "Epoch: 5 | Batch_idx: 30 |  Loss: (0.0268) | Acc: (99.44%) (1233/1240)\n",
      "Epoch: 5 | Batch_idx: 40 |  Loss: (0.0241) | Acc: (99.45%) (1631/1640)\n",
      "Epoch: 5 | Batch_idx: 50 |  Loss: (0.0213) | Acc: (99.46%) (2029/2040)\n",
      "Epoch: 5 | Batch_idx: 60 |  Loss: (0.0189) | Acc: (99.51%) (2428/2440)\n",
      "Epoch: 5 | Batch_idx: 70 |  Loss: (0.0206) | Acc: (99.47%) (2825/2840)\n",
      "Epoch: 5 | Batch_idx: 80 |  Loss: (0.0197) | Acc: (99.48%) (3223/3240)\n",
      "Epoch: 5 | Batch_idx: 90 |  Loss: (0.0193) | Acc: (99.45%) (3620/3640)\n",
      "Epoch: 5 | Batch_idx: 100 |  Loss: (0.0189) | Acc: (99.46%) (4018/4040)\n",
      "Epoch: 5 | Batch_idx: 110 |  Loss: (0.0177) | Acc: (99.50%) (4418/4440)\n",
      "Epoch: 5 | Batch_idx: 120 |  Loss: (0.0168) | Acc: (99.52%) (4817/4840)\n",
      "Epoch: 5 | Batch_idx: 130 |  Loss: (0.0164) | Acc: (99.52%) (5215/5240)\n",
      "Epoch: 5 | Batch_idx: 140 |  Loss: (0.0165) | Acc: (99.50%) (5612/5640)\n",
      "Epoch: 5 | Batch_idx: 150 |  Loss: (0.0164) | Acc: (99.52%) (6011/6040)\n",
      "Epoch: 5 | Batch_idx: 160 |  Loss: (0.0157) | Acc: (99.53%) (6410/6440)\n",
      "Epoch: 5 | Batch_idx: 170 |  Loss: (0.0166) | Acc: (99.53%) (6808/6840)\n",
      "Epoch: 5 | Batch_idx: 180 |  Loss: (0.0161) | Acc: (99.54%) (7207/7240)\n",
      "Epoch: 5 | Batch_idx: 190 |  Loss: (0.0159) | Acc: (99.54%) (7605/7640)\n",
      "Epoch: 5 | Batch_idx: 200 |  Loss: (0.0163) | Acc: (99.53%) (8002/8040)\n",
      "Epoch: 5 | Batch_idx: 210 |  Loss: (0.0163) | Acc: (99.54%) (8401/8440)\n",
      "Epoch: 5 | Batch_idx: 220 |  Loss: (0.0159) | Acc: (99.55%) (8800/8840)\n",
      "Epoch: 5 | Batch_idx: 230 |  Loss: (0.0155) | Acc: (99.56%) (9199/9240)\n",
      "Epoch: 5 | Batch_idx: 240 |  Loss: (0.0154) | Acc: (99.55%) (9597/9640)\n",
      "Epoch: 5 | Batch_idx: 250 |  Loss: (0.0151) | Acc: (99.56%) (9996/10040)\n",
      "Epoch: 5 | Batch_idx: 260 |  Loss: (0.0151) | Acc: (99.56%) (10394/10440)\n",
      "Epoch: 5 | Batch_idx: 270 |  Loss: (0.0148) | Acc: (99.56%) (10792/10840)\n",
      "Epoch: 5 | Batch_idx: 280 |  Loss: (0.0146) | Acc: (99.56%) (11191/11240)\n",
      "Epoch: 5 | Batch_idx: 290 |  Loss: (0.0148) | Acc: (99.54%) (11587/11640)\n",
      "Epoch: 5 | Batch_idx: 300 |  Loss: (0.0151) | Acc: (99.53%) (11983/12040)\n",
      "Epoch: 5 | Batch_idx: 310 |  Loss: (0.0159) | Acc: (99.49%) (12377/12440)\n",
      "Epoch: 5 | Batch_idx: 320 |  Loss: (0.0161) | Acc: (99.48%) (12773/12840)\n",
      "Epoch: 5 | Batch_idx: 330 |  Loss: (0.0159) | Acc: (99.48%) (13171/13240)\n",
      "Epoch: 5 | Batch_idx: 340 |  Loss: (0.0160) | Acc: (99.48%) (13569/13640)\n",
      "Epoch: 5 | Batch_idx: 350 |  Loss: (0.0158) | Acc: (99.49%) (13968/14040)\n",
      "Epoch: 5 | Batch_idx: 360 |  Loss: (0.0160) | Acc: (99.48%) (14365/14440)\n",
      "Epoch: 5 | Batch_idx: 370 |  Loss: (0.0161) | Acc: (99.47%) (14762/14840)\n",
      "Epoch: 5 | Batch_idx: 380 |  Loss: (0.0166) | Acc: (99.46%) (15157/15240)\n",
      "Epoch: 5 | Batch_idx: 390 |  Loss: (0.0164) | Acc: (99.46%) (15555/15640)\n",
      "Epoch: 5 | Batch_idx: 400 |  Loss: (0.0165) | Acc: (99.46%) (15954/16040)\n",
      "Epoch: 5 | Batch_idx: 410 |  Loss: (0.0165) | Acc: (99.45%) (16350/16440)\n",
      "Epoch: 5 | Batch_idx: 420 |  Loss: (0.0163) | Acc: (99.46%) (16749/16840)\n",
      "Epoch: 5 | Batch_idx: 430 |  Loss: (0.0160) | Acc: (99.47%) (17148/17240)\n",
      "Epoch: 5 | Batch_idx: 440 |  Loss: (0.0159) | Acc: (99.47%) (17547/17640)\n",
      "Epoch: 5 | Batch_idx: 450 |  Loss: (0.0160) | Acc: (99.47%) (17944/18040)\n",
      "Epoch: 5 | Batch_idx: 460 |  Loss: (0.0161) | Acc: (99.46%) (18340/18440)\n",
      "Epoch: 5 | Batch_idx: 470 |  Loss: (0.0162) | Acc: (99.45%) (18737/18840)\n",
      "Epoch: 5 | Batch_idx: 480 |  Loss: (0.0162) | Acc: (99.46%) (19136/19240)\n",
      "Epoch: 5 | Batch_idx: 490 |  Loss: (0.0163) | Acc: (99.46%) (19533/19640)\n",
      "Epoch: 5 | Batch_idx: 500 |  Loss: (0.0160) | Acc: (99.47%) (19933/20040)\n",
      "Epoch: 5 | Batch_idx: 510 |  Loss: (0.0161) | Acc: (99.47%) (20331/20440)\n",
      "Epoch: 5 | Batch_idx: 520 |  Loss: (0.0159) | Acc: (99.47%) (20730/20840)\n",
      "Epoch: 5 | Batch_idx: 530 |  Loss: (0.0158) | Acc: (99.48%) (21130/21240)\n",
      "Epoch: 5 | Batch_idx: 540 |  Loss: (0.0157) | Acc: (99.49%) (21529/21640)\n",
      "Epoch: 5 | Batch_idx: 550 |  Loss: (0.0159) | Acc: (99.48%) (21925/22040)\n",
      "Epoch: 5 | Batch_idx: 560 |  Loss: (0.0159) | Acc: (99.47%) (22322/22440)\n",
      "Epoch: 5 | Batch_idx: 570 |  Loss: (0.0164) | Acc: (99.47%) (22719/22840)\n",
      "Epoch: 5 | Batch_idx: 580 |  Loss: (0.0168) | Acc: (99.46%) (23115/23240)\n",
      "Epoch: 5 | Batch_idx: 590 |  Loss: (0.0166) | Acc: (99.46%) (23513/23640)\n",
      "Epoch: 5 | Batch_idx: 600 |  Loss: (0.0165) | Acc: (99.47%) (23912/24040)\n",
      "Epoch: 5 | Batch_idx: 610 |  Loss: (0.0164) | Acc: (99.47%) (24310/24440)\n",
      "Epoch: 5 | Batch_idx: 620 |  Loss: (0.0162) | Acc: (99.48%) (24710/24840)\n",
      "Epoch: 5 | Batch_idx: 630 |  Loss: (0.0161) | Acc: (99.48%) (25109/25240)\n",
      "Epoch: 5 | Batch_idx: 640 |  Loss: (0.0160) | Acc: (99.49%) (25509/25640)\n",
      "Epoch: 5 | Batch_idx: 650 |  Loss: (0.0160) | Acc: (99.49%) (25906/26040)\n",
      "Epoch: 5 | Batch_idx: 660 |  Loss: (0.0158) | Acc: (99.49%) (26306/26440)\n",
      "Epoch: 5 | Batch_idx: 670 |  Loss: (0.0157) | Acc: (99.50%) (26706/26840)\n",
      "Epoch: 5 | Batch_idx: 680 |  Loss: (0.0160) | Acc: (99.48%) (27099/27240)\n",
      "Epoch: 5 | Batch_idx: 690 |  Loss: (0.0160) | Acc: (99.48%) (27497/27640)\n",
      "Epoch: 5 | Batch_idx: 700 |  Loss: (0.0162) | Acc: (99.48%) (27893/28040)\n",
      "Epoch: 5 | Batch_idx: 710 |  Loss: (0.0165) | Acc: (99.47%) (28289/28440)\n",
      "Epoch: 5 | Batch_idx: 720 |  Loss: (0.0165) | Acc: (99.47%) (28687/28840)\n",
      "Epoch: 5 | Batch_idx: 730 |  Loss: (0.0165) | Acc: (99.47%) (29085/29240)\n",
      "Epoch: 5 | Batch_idx: 740 |  Loss: (0.0164) | Acc: (99.48%) (29485/29640)\n",
      "Epoch: 5 | Batch_idx: 750 |  Loss: (0.0164) | Acc: (99.48%) (29883/30040)\n",
      "Epoch: 5 | Batch_idx: 760 |  Loss: (0.0164) | Acc: (99.48%) (30281/30440)\n",
      "Epoch: 5 | Batch_idx: 770 |  Loss: (0.0163) | Acc: (99.47%) (30678/30840)\n",
      "Epoch: 5 | Batch_idx: 780 |  Loss: (0.0164) | Acc: (99.47%) (31073/31240)\n",
      "Epoch: 5 | Batch_idx: 790 |  Loss: (0.0163) | Acc: (99.47%) (31472/31640)\n",
      "Epoch: 5 | Batch_idx: 800 |  Loss: (0.0166) | Acc: (99.45%) (31865/32040)\n",
      "Epoch: 5 | Batch_idx: 810 |  Loss: (0.0167) | Acc: (99.45%) (32261/32440)\n",
      "Epoch: 5 | Batch_idx: 820 |  Loss: (0.0169) | Acc: (99.44%) (32655/32840)\n",
      "Epoch: 5 | Batch_idx: 830 |  Loss: (0.0171) | Acc: (99.43%) (33052/33240)\n",
      "Epoch: 5 | Batch_idx: 840 |  Loss: (0.0170) | Acc: (99.44%) (33452/33640)\n",
      "Epoch: 5 | Batch_idx: 850 |  Loss: (0.0170) | Acc: (99.44%) (33848/34040)\n",
      "Epoch: 5 | Batch_idx: 860 |  Loss: (0.0173) | Acc: (99.43%) (34245/34440)\n",
      "Epoch: 5 | Batch_idx: 870 |  Loss: (0.0173) | Acc: (99.43%) (34643/34840)\n",
      "Epoch: 5 | Batch_idx: 880 |  Loss: (0.0172) | Acc: (99.44%) (35043/35240)\n",
      "Epoch: 5 | Batch_idx: 890 |  Loss: (0.0172) | Acc: (99.44%) (35440/35640)\n",
      "Epoch: 5 | Batch_idx: 900 |  Loss: (0.0171) | Acc: (99.44%) (35838/36040)\n",
      "Epoch: 5 | Batch_idx: 910 |  Loss: (0.0172) | Acc: (99.43%) (36233/36440)\n",
      "Epoch: 5 | Batch_idx: 920 |  Loss: (0.0171) | Acc: (99.44%) (36632/36840)\n",
      "Epoch: 5 | Batch_idx: 930 |  Loss: (0.0170) | Acc: (99.44%) (37032/37240)\n",
      "Epoch: 5 | Batch_idx: 940 |  Loss: (0.0170) | Acc: (99.44%) (37429/37640)\n",
      "Epoch: 5 | Batch_idx: 950 |  Loss: (0.0170) | Acc: (99.44%) (37828/38040)\n",
      "Epoch: 5 | Batch_idx: 960 |  Loss: (0.0169) | Acc: (99.44%) (38226/38440)\n",
      "Epoch: 5 | Batch_idx: 970 |  Loss: (0.0170) | Acc: (99.44%) (38624/38840)\n",
      "Epoch: 5 | Batch_idx: 980 |  Loss: (0.0171) | Acc: (99.44%) (39021/39240)\n",
      "Epoch: 5 | Batch_idx: 990 |  Loss: (0.0173) | Acc: (99.44%) (39417/39640)\n",
      "Epoch: 5 | Batch_idx: 1000 |  Loss: (0.0174) | Acc: (99.44%) (39815/40040)\n",
      "Epoch: 5 | Batch_idx: 1010 |  Loss: (0.0174) | Acc: (99.43%) (40211/40440)\n",
      "Epoch: 5 | Batch_idx: 1020 |  Loss: (0.0174) | Acc: (99.43%) (40609/40840)\n",
      "Epoch: 5 | Batch_idx: 1030 |  Loss: (0.0174) | Acc: (99.43%) (41005/41240)\n",
      "Epoch: 5 | Batch_idx: 1040 |  Loss: (0.0175) | Acc: (99.43%) (41401/41640)\n",
      "Epoch: 5 | Batch_idx: 1050 |  Loss: (0.0176) | Acc: (99.43%) (41799/42040)\n",
      "Epoch: 5 | Batch_idx: 1060 |  Loss: (0.0175) | Acc: (99.43%) (42199/42440)\n",
      "Epoch: 5 | Batch_idx: 1070 |  Loss: (0.0175) | Acc: (99.43%) (42597/42840)\n",
      "Epoch: 5 | Batch_idx: 1080 |  Loss: (0.0176) | Acc: (99.43%) (42992/43240)\n",
      "Epoch: 5 | Batch_idx: 1090 |  Loss: (0.0176) | Acc: (99.43%) (43390/43640)\n",
      "Epoch: 5 | Batch_idx: 1100 |  Loss: (0.0176) | Acc: (99.43%) (43788/44040)\n",
      "Epoch: 5 | Batch_idx: 1110 |  Loss: (0.0176) | Acc: (99.43%) (44187/44440)\n",
      "Epoch: 5 | Batch_idx: 1120 |  Loss: (0.0176) | Acc: (99.43%) (44585/44840)\n",
      "Epoch: 5 | Batch_idx: 1130 |  Loss: (0.0176) | Acc: (99.43%) (44984/45240)\n",
      "Epoch: 5 | Batch_idx: 1140 |  Loss: (0.0176) | Acc: (99.43%) (45381/45640)\n",
      "Epoch: 5 | Batch_idx: 1150 |  Loss: (0.0179) | Acc: (99.42%) (45775/46040)\n",
      "Epoch: 5 | Batch_idx: 1160 |  Loss: (0.0178) | Acc: (99.42%) (46172/46440)\n",
      "Epoch: 5 | Batch_idx: 1170 |  Loss: (0.0177) | Acc: (99.43%) (46571/46840)\n",
      "Epoch: 5 | Batch_idx: 1180 |  Loss: (0.0176) | Acc: (99.43%) (46971/47240)\n",
      "Epoch: 5 | Batch_idx: 1190 |  Loss: (0.0177) | Acc: (99.43%) (47369/47640)\n",
      "Epoch: 5 | Batch_idx: 1200 |  Loss: (0.0176) | Acc: (99.43%) (47768/48040)\n",
      "Epoch: 5 | Batch_idx: 1210 |  Loss: (0.0175) | Acc: (99.43%) (48165/48440)\n",
      "Epoch: 5 | Batch_idx: 1220 |  Loss: (0.0175) | Acc: (99.43%) (48564/48840)\n",
      "Epoch: 5 | Batch_idx: 1230 |  Loss: (0.0174) | Acc: (99.44%) (48963/49240)\n",
      "Epoch: 5 | Batch_idx: 1240 |  Loss: (0.0175) | Acc: (99.43%) (49359/49640)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.1869) | Acc: (95.30%) (9530/10000)\n",
      "Epoch: 6 | Batch_idx: 0 |  Loss: (0.0203) | Acc: (97.50%) (39/40)\n",
      "Epoch: 6 | Batch_idx: 10 |  Loss: (0.0165) | Acc: (99.09%) (436/440)\n",
      "Epoch: 6 | Batch_idx: 20 |  Loss: (0.0187) | Acc: (99.17%) (833/840)\n",
      "Epoch: 6 | Batch_idx: 30 |  Loss: (0.0145) | Acc: (99.44%) (1233/1240)\n",
      "Epoch: 6 | Batch_idx: 40 |  Loss: (0.0116) | Acc: (99.57%) (1633/1640)\n",
      "Epoch: 6 | Batch_idx: 50 |  Loss: (0.0107) | Acc: (99.61%) (2032/2040)\n",
      "Epoch: 6 | Batch_idx: 60 |  Loss: (0.0104) | Acc: (99.67%) (2432/2440)\n",
      "Epoch: 6 | Batch_idx: 70 |  Loss: (0.0096) | Acc: (99.68%) (2831/2840)\n",
      "Epoch: 6 | Batch_idx: 80 |  Loss: (0.0096) | Acc: (99.69%) (3230/3240)\n",
      "Epoch: 6 | Batch_idx: 90 |  Loss: (0.0100) | Acc: (99.70%) (3629/3640)\n",
      "Epoch: 6 | Batch_idx: 100 |  Loss: (0.0103) | Acc: (99.70%) (4028/4040)\n",
      "Epoch: 6 | Batch_idx: 110 |  Loss: (0.0105) | Acc: (99.71%) (4427/4440)\n",
      "Epoch: 6 | Batch_idx: 120 |  Loss: (0.0105) | Acc: (99.71%) (4826/4840)\n",
      "Epoch: 6 | Batch_idx: 130 |  Loss: (0.0115) | Acc: (99.69%) (5224/5240)\n",
      "Epoch: 6 | Batch_idx: 140 |  Loss: (0.0129) | Acc: (99.63%) (5619/5640)\n",
      "Epoch: 6 | Batch_idx: 150 |  Loss: (0.0129) | Acc: (99.64%) (6018/6040)\n",
      "Epoch: 6 | Batch_idx: 160 |  Loss: (0.0129) | Acc: (99.63%) (6416/6440)\n",
      "Epoch: 6 | Batch_idx: 170 |  Loss: (0.0129) | Acc: (99.61%) (6813/6840)\n",
      "Epoch: 6 | Batch_idx: 180 |  Loss: (0.0125) | Acc: (99.61%) (7212/7240)\n",
      "Epoch: 6 | Batch_idx: 190 |  Loss: (0.0124) | Acc: (99.62%) (7611/7640)\n",
      "Epoch: 6 | Batch_idx: 200 |  Loss: (0.0124) | Acc: (99.61%) (8009/8040)\n",
      "Epoch: 6 | Batch_idx: 210 |  Loss: (0.0133) | Acc: (99.56%) (8403/8440)\n",
      "Epoch: 6 | Batch_idx: 220 |  Loss: (0.0132) | Acc: (99.56%) (8801/8840)\n",
      "Epoch: 6 | Batch_idx: 230 |  Loss: (0.0134) | Acc: (99.55%) (9198/9240)\n",
      "Epoch: 6 | Batch_idx: 240 |  Loss: (0.0131) | Acc: (99.56%) (9598/9640)\n",
      "Epoch: 6 | Batch_idx: 250 |  Loss: (0.0128) | Acc: (99.58%) (9998/10040)\n",
      "Epoch: 6 | Batch_idx: 260 |  Loss: (0.0126) | Acc: (99.59%) (10397/10440)\n",
      "Epoch: 6 | Batch_idx: 270 |  Loss: (0.0124) | Acc: (99.59%) (10796/10840)\n",
      "Epoch: 6 | Batch_idx: 280 |  Loss: (0.0130) | Acc: (99.58%) (11193/11240)\n",
      "Epoch: 6 | Batch_idx: 290 |  Loss: (0.0128) | Acc: (99.60%) (11593/11640)\n",
      "Epoch: 6 | Batch_idx: 300 |  Loss: (0.0125) | Acc: (99.61%) (11993/12040)\n",
      "Epoch: 6 | Batch_idx: 310 |  Loss: (0.0122) | Acc: (99.62%) (12393/12440)\n",
      "Epoch: 6 | Batch_idx: 320 |  Loss: (0.0130) | Acc: (99.60%) (12789/12840)\n",
      "Epoch: 6 | Batch_idx: 330 |  Loss: (0.0130) | Acc: (99.60%) (13187/13240)\n",
      "Epoch: 6 | Batch_idx: 340 |  Loss: (0.0129) | Acc: (99.60%) (13586/13640)\n",
      "Epoch: 6 | Batch_idx: 350 |  Loss: (0.0129) | Acc: (99.61%) (13985/14040)\n",
      "Epoch: 6 | Batch_idx: 360 |  Loss: (0.0130) | Acc: (99.61%) (14384/14440)\n",
      "Epoch: 6 | Batch_idx: 370 |  Loss: (0.0128) | Acc: (99.62%) (14783/14840)\n",
      "Epoch: 6 | Batch_idx: 380 |  Loss: (0.0126) | Acc: (99.62%) (15182/15240)\n",
      "Epoch: 6 | Batch_idx: 390 |  Loss: (0.0127) | Acc: (99.62%) (15581/15640)\n",
      "Epoch: 6 | Batch_idx: 400 |  Loss: (0.0130) | Acc: (99.62%) (15979/16040)\n",
      "Epoch: 6 | Batch_idx: 410 |  Loss: (0.0128) | Acc: (99.63%) (16379/16440)\n",
      "Epoch: 6 | Batch_idx: 420 |  Loss: (0.0131) | Acc: (99.63%) (16777/16840)\n",
      "Epoch: 6 | Batch_idx: 430 |  Loss: (0.0130) | Acc: (99.63%) (17176/17240)\n",
      "Epoch: 6 | Batch_idx: 440 |  Loss: (0.0128) | Acc: (99.64%) (17576/17640)\n",
      "Epoch: 6 | Batch_idx: 450 |  Loss: (0.0130) | Acc: (99.63%) (17973/18040)\n",
      "Epoch: 6 | Batch_idx: 460 |  Loss: (0.0131) | Acc: (99.63%) (18371/18440)\n",
      "Epoch: 6 | Batch_idx: 470 |  Loss: (0.0131) | Acc: (99.62%) (18769/18840)\n",
      "Epoch: 6 | Batch_idx: 480 |  Loss: (0.0129) | Acc: (99.63%) (19168/19240)\n",
      "Epoch: 6 | Batch_idx: 490 |  Loss: (0.0128) | Acc: (99.63%) (19568/19640)\n",
      "Epoch: 6 | Batch_idx: 500 |  Loss: (0.0126) | Acc: (99.64%) (19968/20040)\n",
      "Epoch: 6 | Batch_idx: 510 |  Loss: (0.0126) | Acc: (99.64%) (20366/20440)\n",
      "Epoch: 6 | Batch_idx: 520 |  Loss: (0.0125) | Acc: (99.64%) (20765/20840)\n",
      "Epoch: 6 | Batch_idx: 530 |  Loss: (0.0127) | Acc: (99.63%) (21162/21240)\n",
      "Epoch: 6 | Batch_idx: 540 |  Loss: (0.0127) | Acc: (99.63%) (21561/21640)\n",
      "Epoch: 6 | Batch_idx: 550 |  Loss: (0.0126) | Acc: (99.64%) (21960/22040)\n",
      "Epoch: 6 | Batch_idx: 560 |  Loss: (0.0126) | Acc: (99.63%) (22358/22440)\n",
      "Epoch: 6 | Batch_idx: 570 |  Loss: (0.0126) | Acc: (99.64%) (22758/22840)\n",
      "Epoch: 6 | Batch_idx: 580 |  Loss: (0.0124) | Acc: (99.65%) (23158/23240)\n",
      "Epoch: 6 | Batch_idx: 590 |  Loss: (0.0123) | Acc: (99.65%) (23557/23640)\n",
      "Epoch: 6 | Batch_idx: 600 |  Loss: (0.0123) | Acc: (99.64%) (23953/24040)\n",
      "Epoch: 6 | Batch_idx: 610 |  Loss: (0.0126) | Acc: (99.63%) (24350/24440)\n",
      "Epoch: 6 | Batch_idx: 620 |  Loss: (0.0127) | Acc: (99.63%) (24748/24840)\n",
      "Epoch: 6 | Batch_idx: 630 |  Loss: (0.0130) | Acc: (99.62%) (25145/25240)\n",
      "Epoch: 6 | Batch_idx: 640 |  Loss: (0.0130) | Acc: (99.63%) (25544/25640)\n",
      "Epoch: 6 | Batch_idx: 650 |  Loss: (0.0129) | Acc: (99.63%) (25944/26040)\n",
      "Epoch: 6 | Batch_idx: 660 |  Loss: (0.0131) | Acc: (99.63%) (26342/26440)\n",
      "Epoch: 6 | Batch_idx: 670 |  Loss: (0.0130) | Acc: (99.63%) (26742/26840)\n",
      "Epoch: 6 | Batch_idx: 680 |  Loss: (0.0130) | Acc: (99.64%) (27141/27240)\n",
      "Epoch: 6 | Batch_idx: 690 |  Loss: (0.0129) | Acc: (99.64%) (27540/27640)\n",
      "Epoch: 6 | Batch_idx: 700 |  Loss: (0.0129) | Acc: (99.64%) (27938/28040)\n",
      "Epoch: 6 | Batch_idx: 710 |  Loss: (0.0129) | Acc: (99.64%) (28337/28440)\n",
      "Epoch: 6 | Batch_idx: 720 |  Loss: (0.0128) | Acc: (99.64%) (28736/28840)\n",
      "Epoch: 6 | Batch_idx: 730 |  Loss: (0.0128) | Acc: (99.64%) (29134/29240)\n",
      "Epoch: 6 | Batch_idx: 740 |  Loss: (0.0127) | Acc: (99.64%) (29534/29640)\n",
      "Epoch: 6 | Batch_idx: 750 |  Loss: (0.0126) | Acc: (99.65%) (29934/30040)\n",
      "Epoch: 6 | Batch_idx: 760 |  Loss: (0.0126) | Acc: (99.65%) (30332/30440)\n",
      "Epoch: 6 | Batch_idx: 770 |  Loss: (0.0127) | Acc: (99.64%) (30729/30840)\n",
      "Epoch: 6 | Batch_idx: 780 |  Loss: (0.0125) | Acc: (99.64%) (31129/31240)\n",
      "Epoch: 6 | Batch_idx: 790 |  Loss: (0.0125) | Acc: (99.65%) (31528/31640)\n",
      "Epoch: 6 | Batch_idx: 800 |  Loss: (0.0124) | Acc: (99.65%) (31928/32040)\n",
      "Epoch: 6 | Batch_idx: 810 |  Loss: (0.0123) | Acc: (99.65%) (32327/32440)\n",
      "Epoch: 6 | Batch_idx: 820 |  Loss: (0.0123) | Acc: (99.66%) (32727/32840)\n",
      "Epoch: 6 | Batch_idx: 830 |  Loss: (0.0125) | Acc: (99.65%) (33124/33240)\n",
      "Epoch: 6 | Batch_idx: 840 |  Loss: (0.0124) | Acc: (99.66%) (33524/33640)\n",
      "Epoch: 6 | Batch_idx: 850 |  Loss: (0.0124) | Acc: (99.66%) (33923/34040)\n",
      "Epoch: 6 | Batch_idx: 860 |  Loss: (0.0123) | Acc: (99.65%) (34321/34440)\n",
      "Epoch: 6 | Batch_idx: 870 |  Loss: (0.0123) | Acc: (99.66%) (34720/34840)\n",
      "Epoch: 6 | Batch_idx: 880 |  Loss: (0.0122) | Acc: (99.66%) (35119/35240)\n",
      "Epoch: 6 | Batch_idx: 890 |  Loss: (0.0122) | Acc: (99.66%) (35519/35640)\n",
      "Epoch: 6 | Batch_idx: 900 |  Loss: (0.0122) | Acc: (99.66%) (35917/36040)\n",
      "Epoch: 6 | Batch_idx: 910 |  Loss: (0.0121) | Acc: (99.66%) (36315/36440)\n",
      "Epoch: 6 | Batch_idx: 920 |  Loss: (0.0122) | Acc: (99.66%) (36713/36840)\n",
      "Epoch: 6 | Batch_idx: 930 |  Loss: (0.0121) | Acc: (99.66%) (37113/37240)\n",
      "Epoch: 6 | Batch_idx: 940 |  Loss: (0.0120) | Acc: (99.66%) (37513/37640)\n",
      "Epoch: 6 | Batch_idx: 950 |  Loss: (0.0122) | Acc: (99.65%) (37908/38040)\n",
      "Epoch: 6 | Batch_idx: 960 |  Loss: (0.0126) | Acc: (99.65%) (38304/38440)\n",
      "Epoch: 6 | Batch_idx: 970 |  Loss: (0.0125) | Acc: (99.65%) (38703/38840)\n",
      "Epoch: 6 | Batch_idx: 980 |  Loss: (0.0125) | Acc: (99.65%) (39102/39240)\n",
      "Epoch: 6 | Batch_idx: 990 |  Loss: (0.0126) | Acc: (99.65%) (39500/39640)\n",
      "Epoch: 6 | Batch_idx: 1000 |  Loss: (0.0127) | Acc: (99.65%) (39898/40040)\n",
      "Epoch: 6 | Batch_idx: 1010 |  Loss: (0.0126) | Acc: (99.65%) (40298/40440)\n",
      "Epoch: 6 | Batch_idx: 1020 |  Loss: (0.0126) | Acc: (99.65%) (40696/40840)\n",
      "Epoch: 6 | Batch_idx: 1030 |  Loss: (0.0125) | Acc: (99.65%) (41096/41240)\n",
      "Epoch: 6 | Batch_idx: 1040 |  Loss: (0.0124) | Acc: (99.65%) (41496/41640)\n",
      "Epoch: 6 | Batch_idx: 1050 |  Loss: (0.0124) | Acc: (99.66%) (41895/42040)\n",
      "Epoch: 6 | Batch_idx: 1060 |  Loss: (0.0127) | Acc: (99.65%) (42290/42440)\n",
      "Epoch: 6 | Batch_idx: 1070 |  Loss: (0.0126) | Acc: (99.65%) (42688/42840)\n",
      "Epoch: 6 | Batch_idx: 1080 |  Loss: (0.0126) | Acc: (99.65%) (43087/43240)\n",
      "Epoch: 6 | Batch_idx: 1090 |  Loss: (0.0126) | Acc: (99.65%) (43486/43640)\n",
      "Epoch: 6 | Batch_idx: 1100 |  Loss: (0.0126) | Acc: (99.65%) (43884/44040)\n",
      "Epoch: 6 | Batch_idx: 1110 |  Loss: (0.0126) | Acc: (99.64%) (44282/44440)\n",
      "Epoch: 6 | Batch_idx: 1120 |  Loss: (0.0127) | Acc: (99.64%) (44679/44840)\n",
      "Epoch: 6 | Batch_idx: 1130 |  Loss: (0.0127) | Acc: (99.64%) (45078/45240)\n",
      "Epoch: 6 | Batch_idx: 1140 |  Loss: (0.0126) | Acc: (99.64%) (45476/45640)\n",
      "Epoch: 6 | Batch_idx: 1150 |  Loss: (0.0126) | Acc: (99.64%) (45874/46040)\n",
      "Epoch: 6 | Batch_idx: 1160 |  Loss: (0.0126) | Acc: (99.64%) (46273/46440)\n",
      "Epoch: 6 | Batch_idx: 1170 |  Loss: (0.0126) | Acc: (99.64%) (46671/46840)\n",
      "Epoch: 6 | Batch_idx: 1180 |  Loss: (0.0127) | Acc: (99.63%) (47067/47240)\n",
      "Epoch: 6 | Batch_idx: 1190 |  Loss: (0.0127) | Acc: (99.63%) (47466/47640)\n",
      "Epoch: 6 | Batch_idx: 1200 |  Loss: (0.0129) | Acc: (99.63%) (47864/48040)\n",
      "Epoch: 6 | Batch_idx: 1210 |  Loss: (0.0128) | Acc: (99.63%) (48263/48440)\n",
      "Epoch: 6 | Batch_idx: 1220 |  Loss: (0.0128) | Acc: (99.63%) (48661/48840)\n",
      "Epoch: 6 | Batch_idx: 1230 |  Loss: (0.0129) | Acc: (99.63%) (49059/49240)\n",
      "Epoch: 6 | Batch_idx: 1240 |  Loss: (0.0129) | Acc: (99.64%) (49459/49640)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.1802) | Acc: (95.23%) (9523/10000)\n",
      "Epoch: 7 | Batch_idx: 0 |  Loss: (0.0014) | Acc: (100.00%) (40/40)\n",
      "Epoch: 7 | Batch_idx: 10 |  Loss: (0.0051) | Acc: (99.77%) (439/440)\n",
      "Epoch: 7 | Batch_idx: 20 |  Loss: (0.0043) | Acc: (99.88%) (839/840)\n",
      "Epoch: 7 | Batch_idx: 30 |  Loss: (0.0060) | Acc: (99.76%) (1237/1240)\n",
      "Epoch: 7 | Batch_idx: 40 |  Loss: (0.0059) | Acc: (99.82%) (1637/1640)\n",
      "Epoch: 7 | Batch_idx: 50 |  Loss: (0.0101) | Acc: (99.80%) (2036/2040)\n",
      "Epoch: 7 | Batch_idx: 60 |  Loss: (0.0104) | Acc: (99.80%) (2435/2440)\n",
      "Epoch: 7 | Batch_idx: 70 |  Loss: (0.0096) | Acc: (99.82%) (2835/2840)\n",
      "Epoch: 7 | Batch_idx: 80 |  Loss: (0.0088) | Acc: (99.85%) (3235/3240)\n",
      "Epoch: 7 | Batch_idx: 90 |  Loss: (0.0082) | Acc: (99.86%) (3635/3640)\n",
      "Epoch: 7 | Batch_idx: 100 |  Loss: (0.0083) | Acc: (99.85%) (4034/4040)\n",
      "Epoch: 7 | Batch_idx: 110 |  Loss: (0.0084) | Acc: (99.84%) (4433/4440)\n",
      "Epoch: 7 | Batch_idx: 120 |  Loss: (0.0089) | Acc: (99.81%) (4831/4840)\n",
      "Epoch: 7 | Batch_idx: 130 |  Loss: (0.0096) | Acc: (99.81%) (5230/5240)\n",
      "Epoch: 7 | Batch_idx: 140 |  Loss: (0.0095) | Acc: (99.80%) (5629/5640)\n",
      "Epoch: 7 | Batch_idx: 150 |  Loss: (0.0092) | Acc: (99.82%) (6029/6040)\n",
      "Epoch: 7 | Batch_idx: 160 |  Loss: (0.0095) | Acc: (99.78%) (6426/6440)\n",
      "Epoch: 7 | Batch_idx: 170 |  Loss: (0.0092) | Acc: (99.80%) (6826/6840)\n",
      "Epoch: 7 | Batch_idx: 180 |  Loss: (0.0090) | Acc: (99.79%) (7225/7240)\n",
      "Epoch: 7 | Batch_idx: 190 |  Loss: (0.0087) | Acc: (99.80%) (7625/7640)\n",
      "Epoch: 7 | Batch_idx: 200 |  Loss: (0.0087) | Acc: (99.80%) (8024/8040)\n",
      "Epoch: 7 | Batch_idx: 210 |  Loss: (0.0089) | Acc: (99.80%) (8423/8440)\n",
      "Epoch: 7 | Batch_idx: 220 |  Loss: (0.0086) | Acc: (99.81%) (8823/8840)\n",
      "Epoch: 7 | Batch_idx: 230 |  Loss: (0.0083) | Acc: (99.82%) (9223/9240)\n",
      "Epoch: 7 | Batch_idx: 240 |  Loss: (0.0085) | Acc: (99.79%) (9620/9640)\n",
      "Epoch: 7 | Batch_idx: 250 |  Loss: (0.0083) | Acc: (99.80%) (10020/10040)\n",
      "Epoch: 7 | Batch_idx: 260 |  Loss: (0.0081) | Acc: (99.81%) (10420/10440)\n",
      "Epoch: 7 | Batch_idx: 270 |  Loss: (0.0079) | Acc: (99.82%) (10820/10840)\n",
      "Epoch: 7 | Batch_idx: 280 |  Loss: (0.0078) | Acc: (99.81%) (11219/11240)\n",
      "Epoch: 7 | Batch_idx: 290 |  Loss: (0.0079) | Acc: (99.80%) (11617/11640)\n",
      "Epoch: 7 | Batch_idx: 300 |  Loss: (0.0086) | Acc: (99.78%) (12014/12040)\n",
      "Epoch: 7 | Batch_idx: 310 |  Loss: (0.0085) | Acc: (99.79%) (12414/12440)\n",
      "Epoch: 7 | Batch_idx: 320 |  Loss: (0.0084) | Acc: (99.80%) (12814/12840)\n",
      "Epoch: 7 | Batch_idx: 330 |  Loss: (0.0084) | Acc: (99.80%) (13213/13240)\n",
      "Epoch: 7 | Batch_idx: 340 |  Loss: (0.0082) | Acc: (99.80%) (13613/13640)\n",
      "Epoch: 7 | Batch_idx: 350 |  Loss: (0.0081) | Acc: (99.80%) (14012/14040)\n",
      "Epoch: 7 | Batch_idx: 360 |  Loss: (0.0086) | Acc: (99.79%) (14410/14440)\n",
      "Epoch: 7 | Batch_idx: 370 |  Loss: (0.0086) | Acc: (99.79%) (14809/14840)\n",
      "Epoch: 7 | Batch_idx: 380 |  Loss: (0.0085) | Acc: (99.80%) (15209/15240)\n",
      "Epoch: 7 | Batch_idx: 390 |  Loss: (0.0085) | Acc: (99.79%) (15607/15640)\n",
      "Epoch: 7 | Batch_idx: 400 |  Loss: (0.0085) | Acc: (99.79%) (16007/16040)\n",
      "Epoch: 7 | Batch_idx: 410 |  Loss: (0.0085) | Acc: (99.78%) (16404/16440)\n",
      "Epoch: 7 | Batch_idx: 420 |  Loss: (0.0089) | Acc: (99.77%) (16802/16840)\n",
      "Epoch: 7 | Batch_idx: 430 |  Loss: (0.0088) | Acc: (99.78%) (17202/17240)\n",
      "Epoch: 7 | Batch_idx: 440 |  Loss: (0.0086) | Acc: (99.78%) (17602/17640)\n",
      "Epoch: 7 | Batch_idx: 450 |  Loss: (0.0086) | Acc: (99.78%) (18001/18040)\n",
      "Epoch: 7 | Batch_idx: 460 |  Loss: (0.0086) | Acc: (99.78%) (18400/18440)\n",
      "Epoch: 7 | Batch_idx: 470 |  Loss: (0.0085) | Acc: (99.79%) (18800/18840)\n",
      "Epoch: 7 | Batch_idx: 480 |  Loss: (0.0084) | Acc: (99.79%) (19200/19240)\n",
      "Epoch: 7 | Batch_idx: 490 |  Loss: (0.0085) | Acc: (99.79%) (19599/19640)\n",
      "Epoch: 7 | Batch_idx: 500 |  Loss: (0.0083) | Acc: (99.80%) (19999/20040)\n",
      "Epoch: 7 | Batch_idx: 510 |  Loss: (0.0084) | Acc: (99.80%) (20399/20440)\n",
      "Epoch: 7 | Batch_idx: 520 |  Loss: (0.0083) | Acc: (99.80%) (20799/20840)\n",
      "Epoch: 7 | Batch_idx: 530 |  Loss: (0.0082) | Acc: (99.81%) (21199/21240)\n",
      "Epoch: 7 | Batch_idx: 540 |  Loss: (0.0081) | Acc: (99.81%) (21599/21640)\n",
      "Epoch: 7 | Batch_idx: 550 |  Loss: (0.0081) | Acc: (99.81%) (21998/22040)\n",
      "Epoch: 7 | Batch_idx: 560 |  Loss: (0.0080) | Acc: (99.81%) (22398/22440)\n",
      "Epoch: 7 | Batch_idx: 570 |  Loss: (0.0079) | Acc: (99.82%) (22798/22840)\n",
      "Epoch: 7 | Batch_idx: 580 |  Loss: (0.0079) | Acc: (99.81%) (23196/23240)\n",
      "Epoch: 7 | Batch_idx: 590 |  Loss: (0.0079) | Acc: (99.81%) (23596/23640)\n",
      "Epoch: 7 | Batch_idx: 600 |  Loss: (0.0081) | Acc: (99.80%) (23993/24040)\n",
      "Epoch: 7 | Batch_idx: 610 |  Loss: (0.0080) | Acc: (99.80%) (24392/24440)\n",
      "Epoch: 7 | Batch_idx: 620 |  Loss: (0.0081) | Acc: (99.80%) (24791/24840)\n",
      "Epoch: 7 | Batch_idx: 630 |  Loss: (0.0081) | Acc: (99.80%) (25190/25240)\n",
      "Epoch: 7 | Batch_idx: 640 |  Loss: (0.0081) | Acc: (99.80%) (25588/25640)\n",
      "Epoch: 7 | Batch_idx: 650 |  Loss: (0.0083) | Acc: (99.79%) (25985/26040)\n",
      "Epoch: 7 | Batch_idx: 660 |  Loss: (0.0083) | Acc: (99.79%) (26385/26440)\n",
      "Epoch: 7 | Batch_idx: 670 |  Loss: (0.0083) | Acc: (99.79%) (26784/26840)\n",
      "Epoch: 7 | Batch_idx: 680 |  Loss: (0.0082) | Acc: (99.79%) (27184/27240)\n",
      "Epoch: 7 | Batch_idx: 690 |  Loss: (0.0081) | Acc: (99.80%) (27584/27640)\n",
      "Epoch: 7 | Batch_idx: 700 |  Loss: (0.0082) | Acc: (99.79%) (27982/28040)\n",
      "Epoch: 7 | Batch_idx: 710 |  Loss: (0.0083) | Acc: (99.79%) (28380/28440)\n",
      "Epoch: 7 | Batch_idx: 720 |  Loss: (0.0083) | Acc: (99.79%) (28780/28840)\n",
      "Epoch: 7 | Batch_idx: 730 |  Loss: (0.0083) | Acc: (99.79%) (29178/29240)\n",
      "Epoch: 7 | Batch_idx: 740 |  Loss: (0.0084) | Acc: (99.78%) (29576/29640)\n",
      "Epoch: 7 | Batch_idx: 750 |  Loss: (0.0085) | Acc: (99.78%) (29975/30040)\n",
      "Epoch: 7 | Batch_idx: 760 |  Loss: (0.0084) | Acc: (99.78%) (30374/30440)\n",
      "Epoch: 7 | Batch_idx: 770 |  Loss: (0.0084) | Acc: (99.78%) (30772/30840)\n",
      "Epoch: 7 | Batch_idx: 780 |  Loss: (0.0085) | Acc: (99.78%) (31170/31240)\n",
      "Epoch: 7 | Batch_idx: 790 |  Loss: (0.0085) | Acc: (99.78%) (31569/31640)\n",
      "Epoch: 7 | Batch_idx: 800 |  Loss: (0.0085) | Acc: (99.78%) (31968/32040)\n",
      "Epoch: 7 | Batch_idx: 810 |  Loss: (0.0086) | Acc: (99.77%) (32366/32440)\n",
      "Epoch: 7 | Batch_idx: 820 |  Loss: (0.0086) | Acc: (99.77%) (32765/32840)\n",
      "Epoch: 7 | Batch_idx: 830 |  Loss: (0.0085) | Acc: (99.77%) (33165/33240)\n",
      "Epoch: 7 | Batch_idx: 840 |  Loss: (0.0085) | Acc: (99.77%) (33564/33640)\n",
      "Epoch: 7 | Batch_idx: 850 |  Loss: (0.0089) | Acc: (99.76%) (33958/34040)\n",
      "Epoch: 7 | Batch_idx: 860 |  Loss: (0.0088) | Acc: (99.76%) (34358/34440)\n",
      "Epoch: 7 | Batch_idx: 870 |  Loss: (0.0088) | Acc: (99.76%) (34758/34840)\n",
      "Epoch: 7 | Batch_idx: 880 |  Loss: (0.0088) | Acc: (99.76%) (35157/35240)\n",
      "Epoch: 7 | Batch_idx: 890 |  Loss: (0.0087) | Acc: (99.77%) (35557/35640)\n",
      "Epoch: 7 | Batch_idx: 900 |  Loss: (0.0087) | Acc: (99.77%) (35956/36040)\n",
      "Epoch: 7 | Batch_idx: 910 |  Loss: (0.0087) | Acc: (99.76%) (36354/36440)\n",
      "Epoch: 7 | Batch_idx: 920 |  Loss: (0.0087) | Acc: (99.76%) (36752/36840)\n",
      "Epoch: 7 | Batch_idx: 930 |  Loss: (0.0087) | Acc: (99.76%) (37151/37240)\n",
      "Epoch: 7 | Batch_idx: 940 |  Loss: (0.0086) | Acc: (99.76%) (37551/37640)\n",
      "Epoch: 7 | Batch_idx: 950 |  Loss: (0.0086) | Acc: (99.77%) (37951/38040)\n",
      "Epoch: 7 | Batch_idx: 960 |  Loss: (0.0088) | Acc: (99.76%) (38349/38440)\n",
      "Epoch: 7 | Batch_idx: 970 |  Loss: (0.0088) | Acc: (99.76%) (38747/38840)\n",
      "Epoch: 7 | Batch_idx: 980 |  Loss: (0.0087) | Acc: (99.76%) (39147/39240)\n",
      "Epoch: 7 | Batch_idx: 990 |  Loss: (0.0088) | Acc: (99.76%) (39545/39640)\n",
      "Epoch: 7 | Batch_idx: 1000 |  Loss: (0.0088) | Acc: (99.76%) (39942/40040)\n",
      "Epoch: 7 | Batch_idx: 1010 |  Loss: (0.0088) | Acc: (99.75%) (40340/40440)\n",
      "Epoch: 7 | Batch_idx: 1020 |  Loss: (0.0088) | Acc: (99.76%) (40740/40840)\n",
      "Epoch: 7 | Batch_idx: 1030 |  Loss: (0.0088) | Acc: (99.76%) (41139/41240)\n",
      "Epoch: 7 | Batch_idx: 1040 |  Loss: (0.0088) | Acc: (99.75%) (41537/41640)\n",
      "Epoch: 7 | Batch_idx: 1050 |  Loss: (0.0088) | Acc: (99.75%) (41936/42040)\n",
      "Epoch: 7 | Batch_idx: 1060 |  Loss: (0.0089) | Acc: (99.75%) (42332/42440)\n",
      "Epoch: 7 | Batch_idx: 1070 |  Loss: (0.0090) | Acc: (99.74%) (42730/42840)\n",
      "Epoch: 7 | Batch_idx: 1080 |  Loss: (0.0089) | Acc: (99.75%) (43130/43240)\n",
      "Epoch: 7 | Batch_idx: 1090 |  Loss: (0.0090) | Acc: (99.75%) (43529/43640)\n",
      "Epoch: 7 | Batch_idx: 1100 |  Loss: (0.0089) | Acc: (99.75%) (43929/44040)\n",
      "Epoch: 7 | Batch_idx: 1110 |  Loss: (0.0090) | Acc: (99.75%) (44328/44440)\n",
      "Epoch: 7 | Batch_idx: 1120 |  Loss: (0.0090) | Acc: (99.75%) (44726/44840)\n",
      "Epoch: 7 | Batch_idx: 1130 |  Loss: (0.0090) | Acc: (99.74%) (45124/45240)\n",
      "Epoch: 7 | Batch_idx: 1140 |  Loss: (0.0090) | Acc: (99.75%) (45524/45640)\n",
      "Epoch: 7 | Batch_idx: 1150 |  Loss: (0.0089) | Acc: (99.75%) (45924/46040)\n",
      "Epoch: 7 | Batch_idx: 1160 |  Loss: (0.0090) | Acc: (99.74%) (46321/46440)\n",
      "Epoch: 7 | Batch_idx: 1170 |  Loss: (0.0090) | Acc: (99.74%) (46720/46840)\n",
      "Epoch: 7 | Batch_idx: 1180 |  Loss: (0.0090) | Acc: (99.74%) (47118/47240)\n",
      "Epoch: 7 | Batch_idx: 1190 |  Loss: (0.0090) | Acc: (99.74%) (47518/47640)\n",
      "Epoch: 7 | Batch_idx: 1200 |  Loss: (0.0090) | Acc: (99.74%) (47916/48040)\n",
      "Epoch: 7 | Batch_idx: 1210 |  Loss: (0.0090) | Acc: (99.74%) (48314/48440)\n",
      "Epoch: 7 | Batch_idx: 1220 |  Loss: (0.0090) | Acc: (99.74%) (48714/48840)\n",
      "Epoch: 7 | Batch_idx: 1230 |  Loss: (0.0090) | Acc: (99.74%) (49113/49240)\n",
      "Epoch: 7 | Batch_idx: 1240 |  Loss: (0.0089) | Acc: (99.74%) (49512/49640)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.1837) | Acc: (95.65%) (9565/10000)\n",
      "Epoch: 8 | Batch_idx: 0 |  Loss: (0.0014) | Acc: (100.00%) (40/40)\n",
      "Epoch: 8 | Batch_idx: 10 |  Loss: (0.0017) | Acc: (100.00%) (440/440)\n",
      "Epoch: 8 | Batch_idx: 20 |  Loss: (0.0132) | Acc: (99.40%) (835/840)\n",
      "Epoch: 8 | Batch_idx: 30 |  Loss: (0.0109) | Acc: (99.60%) (1235/1240)\n",
      "Epoch: 8 | Batch_idx: 40 |  Loss: (0.0114) | Acc: (99.57%) (1633/1640)\n",
      "Epoch: 8 | Batch_idx: 50 |  Loss: (0.0107) | Acc: (99.61%) (2032/2040)\n",
      "Epoch: 8 | Batch_idx: 60 |  Loss: (0.0095) | Acc: (99.67%) (2432/2440)\n",
      "Epoch: 8 | Batch_idx: 70 |  Loss: (0.0086) | Acc: (99.68%) (2831/2840)\n",
      "Epoch: 8 | Batch_idx: 80 |  Loss: (0.0082) | Acc: (99.69%) (3230/3240)\n",
      "Epoch: 8 | Batch_idx: 90 |  Loss: (0.0075) | Acc: (99.73%) (3630/3640)\n",
      "Epoch: 8 | Batch_idx: 100 |  Loss: (0.0079) | Acc: (99.73%) (4029/4040)\n",
      "Epoch: 8 | Batch_idx: 110 |  Loss: (0.0073) | Acc: (99.75%) (4429/4440)\n",
      "Epoch: 8 | Batch_idx: 120 |  Loss: (0.0076) | Acc: (99.75%) (4828/4840)\n",
      "Epoch: 8 | Batch_idx: 130 |  Loss: (0.0074) | Acc: (99.75%) (5227/5240)\n",
      "Epoch: 8 | Batch_idx: 140 |  Loss: (0.0072) | Acc: (99.77%) (5627/5640)\n",
      "Epoch: 8 | Batch_idx: 150 |  Loss: (0.0069) | Acc: (99.78%) (6027/6040)\n",
      "Epoch: 8 | Batch_idx: 160 |  Loss: (0.0073) | Acc: (99.78%) (6426/6440)\n",
      "Epoch: 8 | Batch_idx: 170 |  Loss: (0.0074) | Acc: (99.78%) (6825/6840)\n",
      "Epoch: 8 | Batch_idx: 180 |  Loss: (0.0076) | Acc: (99.77%) (7223/7240)\n",
      "Epoch: 8 | Batch_idx: 190 |  Loss: (0.0075) | Acc: (99.76%) (7622/7640)\n",
      "Epoch: 8 | Batch_idx: 200 |  Loss: (0.0078) | Acc: (99.75%) (8020/8040)\n",
      "Epoch: 8 | Batch_idx: 210 |  Loss: (0.0077) | Acc: (99.75%) (8419/8440)\n",
      "Epoch: 8 | Batch_idx: 220 |  Loss: (0.0084) | Acc: (99.73%) (8816/8840)\n",
      "Epoch: 8 | Batch_idx: 230 |  Loss: (0.0082) | Acc: (99.74%) (9216/9240)\n",
      "Epoch: 8 | Batch_idx: 240 |  Loss: (0.0084) | Acc: (99.74%) (9615/9640)\n",
      "Epoch: 8 | Batch_idx: 250 |  Loss: (0.0081) | Acc: (99.75%) (10015/10040)\n",
      "Epoch: 8 | Batch_idx: 260 |  Loss: (0.0079) | Acc: (99.76%) (10415/10440)\n",
      "Epoch: 8 | Batch_idx: 270 |  Loss: (0.0081) | Acc: (99.76%) (10814/10840)\n",
      "Epoch: 8 | Batch_idx: 280 |  Loss: (0.0082) | Acc: (99.76%) (11213/11240)\n",
      "Epoch: 8 | Batch_idx: 290 |  Loss: (0.0080) | Acc: (99.77%) (11613/11640)\n",
      "Epoch: 8 | Batch_idx: 300 |  Loss: (0.0079) | Acc: (99.77%) (12012/12040)\n",
      "Epoch: 8 | Batch_idx: 310 |  Loss: (0.0078) | Acc: (99.77%) (12412/12440)\n",
      "Epoch: 8 | Batch_idx: 320 |  Loss: (0.0076) | Acc: (99.78%) (12812/12840)\n",
      "Epoch: 8 | Batch_idx: 330 |  Loss: (0.0077) | Acc: (99.78%) (13211/13240)\n",
      "Epoch: 8 | Batch_idx: 340 |  Loss: (0.0076) | Acc: (99.77%) (13609/13640)\n",
      "Epoch: 8 | Batch_idx: 350 |  Loss: (0.0076) | Acc: (99.77%) (14008/14040)\n",
      "Epoch: 8 | Batch_idx: 360 |  Loss: (0.0075) | Acc: (99.78%) (14408/14440)\n",
      "Epoch: 8 | Batch_idx: 370 |  Loss: (0.0080) | Acc: (99.76%) (14804/14840)\n",
      "Epoch: 8 | Batch_idx: 380 |  Loss: (0.0079) | Acc: (99.76%) (15203/15240)\n",
      "Epoch: 8 | Batch_idx: 390 |  Loss: (0.0081) | Acc: (99.76%) (15602/15640)\n",
      "Epoch: 8 | Batch_idx: 400 |  Loss: (0.0080) | Acc: (99.76%) (16002/16040)\n",
      "Epoch: 8 | Batch_idx: 410 |  Loss: (0.0081) | Acc: (99.76%) (16400/16440)\n",
      "Epoch: 8 | Batch_idx: 420 |  Loss: (0.0087) | Acc: (99.74%) (16796/16840)\n",
      "Epoch: 8 | Batch_idx: 430 |  Loss: (0.0086) | Acc: (99.74%) (17195/17240)\n",
      "Epoch: 8 | Batch_idx: 440 |  Loss: (0.0086) | Acc: (99.74%) (17594/17640)\n",
      "Epoch: 8 | Batch_idx: 450 |  Loss: (0.0085) | Acc: (99.74%) (17993/18040)\n",
      "Epoch: 8 | Batch_idx: 460 |  Loss: (0.0084) | Acc: (99.75%) (18393/18440)\n",
      "Epoch: 8 | Batch_idx: 470 |  Loss: (0.0083) | Acc: (99.75%) (18792/18840)\n",
      "Epoch: 8 | Batch_idx: 480 |  Loss: (0.0083) | Acc: (99.75%) (19192/19240)\n",
      "Epoch: 8 | Batch_idx: 490 |  Loss: (0.0084) | Acc: (99.74%) (19589/19640)\n",
      "Epoch: 8 | Batch_idx: 500 |  Loss: (0.0084) | Acc: (99.74%) (19988/20040)\n",
      "Epoch: 8 | Batch_idx: 510 |  Loss: (0.0084) | Acc: (99.74%) (20386/20440)\n",
      "Epoch: 8 | Batch_idx: 520 |  Loss: (0.0083) | Acc: (99.74%) (20786/20840)\n",
      "Epoch: 8 | Batch_idx: 530 |  Loss: (0.0084) | Acc: (99.74%) (21184/21240)\n",
      "Epoch: 8 | Batch_idx: 540 |  Loss: (0.0084) | Acc: (99.74%) (21583/21640)\n",
      "Epoch: 8 | Batch_idx: 550 |  Loss: (0.0084) | Acc: (99.73%) (21981/22040)\n",
      "Epoch: 8 | Batch_idx: 560 |  Loss: (0.0083) | Acc: (99.74%) (22381/22440)\n",
      "Epoch: 8 | Batch_idx: 570 |  Loss: (0.0083) | Acc: (99.73%) (22779/22840)\n",
      "Epoch: 8 | Batch_idx: 580 |  Loss: (0.0083) | Acc: (99.73%) (23177/23240)\n",
      "Epoch: 8 | Batch_idx: 590 |  Loss: (0.0083) | Acc: (99.73%) (23577/23640)\n",
      "Epoch: 8 | Batch_idx: 600 |  Loss: (0.0082) | Acc: (99.74%) (23977/24040)\n",
      "Epoch: 8 | Batch_idx: 610 |  Loss: (0.0083) | Acc: (99.74%) (24376/24440)\n",
      "Epoch: 8 | Batch_idx: 620 |  Loss: (0.0082) | Acc: (99.74%) (24775/24840)\n",
      "Epoch: 8 | Batch_idx: 630 |  Loss: (0.0083) | Acc: (99.73%) (25173/25240)\n",
      "Epoch: 8 | Batch_idx: 640 |  Loss: (0.0083) | Acc: (99.73%) (25572/25640)\n",
      "Epoch: 8 | Batch_idx: 650 |  Loss: (0.0082) | Acc: (99.74%) (25971/26040)\n",
      "Epoch: 8 | Batch_idx: 660 |  Loss: (0.0082) | Acc: (99.74%) (26371/26440)\n",
      "Epoch: 8 | Batch_idx: 670 |  Loss: (0.0082) | Acc: (99.74%) (26770/26840)\n",
      "Epoch: 8 | Batch_idx: 680 |  Loss: (0.0082) | Acc: (99.74%) (27169/27240)\n",
      "Epoch: 8 | Batch_idx: 690 |  Loss: (0.0083) | Acc: (99.73%) (27565/27640)\n",
      "Epoch: 8 | Batch_idx: 700 |  Loss: (0.0083) | Acc: (99.73%) (27965/28040)\n",
      "Epoch: 8 | Batch_idx: 710 |  Loss: (0.0082) | Acc: (99.73%) (28364/28440)\n",
      "Epoch: 8 | Batch_idx: 720 |  Loss: (0.0082) | Acc: (99.74%) (28764/28840)\n",
      "Epoch: 8 | Batch_idx: 730 |  Loss: (0.0081) | Acc: (99.74%) (29163/29240)\n",
      "Epoch: 8 | Batch_idx: 740 |  Loss: (0.0080) | Acc: (99.74%) (29563/29640)\n",
      "Epoch: 8 | Batch_idx: 750 |  Loss: (0.0080) | Acc: (99.74%) (29963/30040)\n",
      "Epoch: 8 | Batch_idx: 760 |  Loss: (0.0079) | Acc: (99.75%) (30363/30440)\n",
      "Epoch: 8 | Batch_idx: 770 |  Loss: (0.0079) | Acc: (99.75%) (30762/30840)\n",
      "Epoch: 8 | Batch_idx: 780 |  Loss: (0.0079) | Acc: (99.75%) (31161/31240)\n",
      "Epoch: 8 | Batch_idx: 790 |  Loss: (0.0078) | Acc: (99.75%) (31561/31640)\n",
      "Epoch: 8 | Batch_idx: 800 |  Loss: (0.0077) | Acc: (99.75%) (31961/32040)\n",
      "Epoch: 8 | Batch_idx: 810 |  Loss: (0.0078) | Acc: (99.75%) (32360/32440)\n",
      "Epoch: 8 | Batch_idx: 820 |  Loss: (0.0083) | Acc: (99.74%) (32755/32840)\n",
      "Epoch: 8 | Batch_idx: 830 |  Loss: (0.0083) | Acc: (99.74%) (33154/33240)\n",
      "Epoch: 8 | Batch_idx: 840 |  Loss: (0.0083) | Acc: (99.74%) (33554/33640)\n",
      "Epoch: 8 | Batch_idx: 850 |  Loss: (0.0083) | Acc: (99.74%) (33953/34040)\n",
      "Epoch: 8 | Batch_idx: 860 |  Loss: (0.0083) | Acc: (99.74%) (34352/34440)\n",
      "Epoch: 8 | Batch_idx: 870 |  Loss: (0.0082) | Acc: (99.74%) (34751/34840)\n",
      "Epoch: 8 | Batch_idx: 880 |  Loss: (0.0082) | Acc: (99.75%) (35151/35240)\n",
      "Epoch: 8 | Batch_idx: 890 |  Loss: (0.0083) | Acc: (99.74%) (35549/35640)\n",
      "Epoch: 8 | Batch_idx: 900 |  Loss: (0.0083) | Acc: (99.74%) (35948/36040)\n",
      "Epoch: 8 | Batch_idx: 910 |  Loss: (0.0082) | Acc: (99.75%) (36348/36440)\n",
      "Epoch: 8 | Batch_idx: 920 |  Loss: (0.0081) | Acc: (99.75%) (36748/36840)\n",
      "Epoch: 8 | Batch_idx: 930 |  Loss: (0.0082) | Acc: (99.75%) (37147/37240)\n",
      "Epoch: 8 | Batch_idx: 940 |  Loss: (0.0082) | Acc: (99.75%) (37545/37640)\n",
      "Epoch: 8 | Batch_idx: 950 |  Loss: (0.0082) | Acc: (99.75%) (37943/38040)\n",
      "Epoch: 8 | Batch_idx: 960 |  Loss: (0.0082) | Acc: (99.74%) (38341/38440)\n",
      "Epoch: 8 | Batch_idx: 970 |  Loss: (0.0083) | Acc: (99.74%) (38739/38840)\n",
      "Epoch: 8 | Batch_idx: 980 |  Loss: (0.0083) | Acc: (99.74%) (39138/39240)\n",
      "Epoch: 8 | Batch_idx: 990 |  Loss: (0.0082) | Acc: (99.74%) (39538/39640)\n",
      "Epoch: 8 | Batch_idx: 1000 |  Loss: (0.0082) | Acc: (99.74%) (39937/40040)\n",
      "Epoch: 8 | Batch_idx: 1010 |  Loss: (0.0081) | Acc: (99.75%) (40337/40440)\n",
      "Epoch: 8 | Batch_idx: 1020 |  Loss: (0.0082) | Acc: (99.74%) (40735/40840)\n",
      "Epoch: 8 | Batch_idx: 1030 |  Loss: (0.0081) | Acc: (99.75%) (41135/41240)\n",
      "Epoch: 8 | Batch_idx: 1040 |  Loss: (0.0081) | Acc: (99.75%) (41534/41640)\n",
      "Epoch: 8 | Batch_idx: 1050 |  Loss: (0.0080) | Acc: (99.75%) (41934/42040)\n",
      "Epoch: 8 | Batch_idx: 1060 |  Loss: (0.0080) | Acc: (99.75%) (42333/42440)\n",
      "Epoch: 8 | Batch_idx: 1070 |  Loss: (0.0080) | Acc: (99.75%) (42733/42840)\n",
      "Epoch: 8 | Batch_idx: 1080 |  Loss: (0.0080) | Acc: (99.75%) (43132/43240)\n",
      "Epoch: 8 | Batch_idx: 1090 |  Loss: (0.0080) | Acc: (99.75%) (43532/43640)\n",
      "Epoch: 8 | Batch_idx: 1100 |  Loss: (0.0081) | Acc: (99.75%) (43929/44040)\n",
      "Epoch: 8 | Batch_idx: 1110 |  Loss: (0.0080) | Acc: (99.75%) (44329/44440)\n",
      "Epoch: 8 | Batch_idx: 1120 |  Loss: (0.0080) | Acc: (99.75%) (44728/44840)\n",
      "Epoch: 8 | Batch_idx: 1130 |  Loss: (0.0080) | Acc: (99.75%) (45127/45240)\n",
      "Epoch: 8 | Batch_idx: 1140 |  Loss: (0.0080) | Acc: (99.75%) (45527/45640)\n",
      "Epoch: 8 | Batch_idx: 1150 |  Loss: (0.0080) | Acc: (99.75%) (45926/46040)\n",
      "Epoch: 8 | Batch_idx: 1160 |  Loss: (0.0080) | Acc: (99.75%) (46324/46440)\n",
      "Epoch: 8 | Batch_idx: 1170 |  Loss: (0.0079) | Acc: (99.75%) (46724/46840)\n",
      "Epoch: 8 | Batch_idx: 1180 |  Loss: (0.0079) | Acc: (99.75%) (47123/47240)\n",
      "Epoch: 8 | Batch_idx: 1190 |  Loss: (0.0079) | Acc: (99.75%) (47522/47640)\n",
      "Epoch: 8 | Batch_idx: 1200 |  Loss: (0.0079) | Acc: (99.75%) (47921/48040)\n",
      "Epoch: 8 | Batch_idx: 1210 |  Loss: (0.0079) | Acc: (99.75%) (48320/48440)\n",
      "Epoch: 8 | Batch_idx: 1220 |  Loss: (0.0079) | Acc: (99.75%) (48719/48840)\n",
      "Epoch: 8 | Batch_idx: 1230 |  Loss: (0.0079) | Acc: (99.75%) (49117/49240)\n",
      "Epoch: 8 | Batch_idx: 1240 |  Loss: (0.0079) | Acc: (99.75%) (49516/49640)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.1950) | Acc: (95.32%) (9532/10000)\n",
      "Epoch: 9 | Batch_idx: 0 |  Loss: (0.0005) | Acc: (100.00%) (40/40)\n",
      "Epoch: 9 | Batch_idx: 10 |  Loss: (0.0035) | Acc: (100.00%) (440/440)\n",
      "Epoch: 9 | Batch_idx: 20 |  Loss: (0.0054) | Acc: (99.88%) (839/840)\n",
      "Epoch: 9 | Batch_idx: 30 |  Loss: (0.0062) | Acc: (99.84%) (1238/1240)\n",
      "Epoch: 9 | Batch_idx: 40 |  Loss: (0.0065) | Acc: (99.82%) (1637/1640)\n",
      "Epoch: 9 | Batch_idx: 50 |  Loss: (0.0061) | Acc: (99.80%) (2036/2040)\n",
      "Epoch: 9 | Batch_idx: 60 |  Loss: (0.0066) | Acc: (99.80%) (2435/2440)\n",
      "Epoch: 9 | Batch_idx: 70 |  Loss: (0.0078) | Acc: (99.79%) (2834/2840)\n",
      "Epoch: 9 | Batch_idx: 80 |  Loss: (0.0076) | Acc: (99.78%) (3233/3240)\n",
      "Epoch: 9 | Batch_idx: 90 |  Loss: (0.0069) | Acc: (99.81%) (3633/3640)\n",
      "Epoch: 9 | Batch_idx: 100 |  Loss: (0.0065) | Acc: (99.83%) (4033/4040)\n",
      "Epoch: 9 | Batch_idx: 110 |  Loss: (0.0064) | Acc: (99.84%) (4433/4440)\n",
      "Epoch: 9 | Batch_idx: 120 |  Loss: (0.0060) | Acc: (99.86%) (4833/4840)\n",
      "Epoch: 9 | Batch_idx: 130 |  Loss: (0.0058) | Acc: (99.87%) (5233/5240)\n",
      "Epoch: 9 | Batch_idx: 140 |  Loss: (0.0056) | Acc: (99.88%) (5633/5640)\n",
      "Epoch: 9 | Batch_idx: 150 |  Loss: (0.0059) | Acc: (99.85%) (6031/6040)\n",
      "Epoch: 9 | Batch_idx: 160 |  Loss: (0.0057) | Acc: (99.86%) (6431/6440)\n",
      "Epoch: 9 | Batch_idx: 170 |  Loss: (0.0063) | Acc: (99.82%) (6828/6840)\n",
      "Epoch: 9 | Batch_idx: 180 |  Loss: (0.0061) | Acc: (99.83%) (7228/7240)\n",
      "Epoch: 9 | Batch_idx: 190 |  Loss: (0.0065) | Acc: (99.80%) (7625/7640)\n",
      "Epoch: 9 | Batch_idx: 200 |  Loss: (0.0063) | Acc: (99.81%) (8025/8040)\n",
      "Epoch: 9 | Batch_idx: 210 |  Loss: (0.0065) | Acc: (99.80%) (8423/8440)\n",
      "Epoch: 9 | Batch_idx: 220 |  Loss: (0.0068) | Acc: (99.80%) (8822/8840)\n",
      "Epoch: 9 | Batch_idx: 230 |  Loss: (0.0068) | Acc: (99.79%) (9221/9240)\n",
      "Epoch: 9 | Batch_idx: 240 |  Loss: (0.0069) | Acc: (99.79%) (9620/9640)\n",
      "Epoch: 9 | Batch_idx: 250 |  Loss: (0.0069) | Acc: (99.79%) (10019/10040)\n",
      "Epoch: 9 | Batch_idx: 260 |  Loss: (0.0067) | Acc: (99.80%) (10419/10440)\n",
      "Epoch: 9 | Batch_idx: 270 |  Loss: (0.0067) | Acc: (99.80%) (10818/10840)\n",
      "Epoch: 9 | Batch_idx: 280 |  Loss: (0.0068) | Acc: (99.79%) (11216/11240)\n",
      "Epoch: 9 | Batch_idx: 290 |  Loss: (0.0066) | Acc: (99.79%) (11616/11640)\n",
      "Epoch: 9 | Batch_idx: 300 |  Loss: (0.0065) | Acc: (99.79%) (12015/12040)\n",
      "Epoch: 9 | Batch_idx: 310 |  Loss: (0.0066) | Acc: (99.79%) (12414/12440)\n",
      "Epoch: 9 | Batch_idx: 320 |  Loss: (0.0068) | Acc: (99.78%) (12812/12840)\n",
      "Epoch: 9 | Batch_idx: 330 |  Loss: (0.0066) | Acc: (99.79%) (13212/13240)\n",
      "Epoch: 9 | Batch_idx: 340 |  Loss: (0.0066) | Acc: (99.78%) (13610/13640)\n",
      "Epoch: 9 | Batch_idx: 350 |  Loss: (0.0068) | Acc: (99.78%) (14009/14040)\n",
      "Epoch: 9 | Batch_idx: 360 |  Loss: (0.0069) | Acc: (99.77%) (14407/14440)\n",
      "Epoch: 9 | Batch_idx: 370 |  Loss: (0.0069) | Acc: (99.78%) (14807/14840)\n",
      "Epoch: 9 | Batch_idx: 380 |  Loss: (0.0070) | Acc: (99.77%) (15205/15240)\n",
      "Epoch: 9 | Batch_idx: 390 |  Loss: (0.0069) | Acc: (99.78%) (15605/15640)\n",
      "Epoch: 9 | Batch_idx: 400 |  Loss: (0.0067) | Acc: (99.78%) (16005/16040)\n",
      "Epoch: 9 | Batch_idx: 410 |  Loss: (0.0067) | Acc: (99.78%) (16404/16440)\n",
      "Epoch: 9 | Batch_idx: 420 |  Loss: (0.0066) | Acc: (99.79%) (16804/16840)\n",
      "Epoch: 9 | Batch_idx: 430 |  Loss: (0.0066) | Acc: (99.79%) (17203/17240)\n",
      "Epoch: 9 | Batch_idx: 440 |  Loss: (0.0065) | Acc: (99.79%) (17603/17640)\n",
      "Epoch: 9 | Batch_idx: 450 |  Loss: (0.0064) | Acc: (99.79%) (18003/18040)\n",
      "Epoch: 9 | Batch_idx: 460 |  Loss: (0.0063) | Acc: (99.80%) (18403/18440)\n",
      "Epoch: 9 | Batch_idx: 470 |  Loss: (0.0063) | Acc: (99.79%) (18801/18840)\n",
      "Epoch: 9 | Batch_idx: 480 |  Loss: (0.0062) | Acc: (99.80%) (19201/19240)\n",
      "Epoch: 9 | Batch_idx: 490 |  Loss: (0.0063) | Acc: (99.79%) (19599/19640)\n",
      "Epoch: 9 | Batch_idx: 500 |  Loss: (0.0062) | Acc: (99.80%) (19999/20040)\n",
      "Epoch: 9 | Batch_idx: 510 |  Loss: (0.0062) | Acc: (99.79%) (20398/20440)\n",
      "Epoch: 9 | Batch_idx: 520 |  Loss: (0.0061) | Acc: (99.79%) (20797/20840)\n",
      "Epoch: 9 | Batch_idx: 530 |  Loss: (0.0061) | Acc: (99.80%) (21197/21240)\n",
      "Epoch: 9 | Batch_idx: 540 |  Loss: (0.0060) | Acc: (99.80%) (21597/21640)\n",
      "Epoch: 9 | Batch_idx: 550 |  Loss: (0.0061) | Acc: (99.80%) (21996/22040)\n",
      "Epoch: 9 | Batch_idx: 560 |  Loss: (0.0061) | Acc: (99.80%) (22395/22440)\n",
      "Epoch: 9 | Batch_idx: 570 |  Loss: (0.0061) | Acc: (99.80%) (22794/22840)\n",
      "Epoch: 9 | Batch_idx: 580 |  Loss: (0.0060) | Acc: (99.80%) (23194/23240)\n",
      "Epoch: 9 | Batch_idx: 590 |  Loss: (0.0060) | Acc: (99.81%) (23594/23640)\n",
      "Epoch: 9 | Batch_idx: 600 |  Loss: (0.0060) | Acc: (99.81%) (23994/24040)\n",
      "Epoch: 9 | Batch_idx: 610 |  Loss: (0.0064) | Acc: (99.80%) (24390/24440)\n",
      "Epoch: 9 | Batch_idx: 620 |  Loss: (0.0064) | Acc: (99.79%) (24789/24840)\n",
      "Epoch: 9 | Batch_idx: 630 |  Loss: (0.0063) | Acc: (99.80%) (25189/25240)\n",
      "Epoch: 9 | Batch_idx: 640 |  Loss: (0.0063) | Acc: (99.80%) (25589/25640)\n",
      "Epoch: 9 | Batch_idx: 650 |  Loss: (0.0062) | Acc: (99.80%) (25989/26040)\n",
      "Epoch: 9 | Batch_idx: 660 |  Loss: (0.0061) | Acc: (99.81%) (26389/26440)\n",
      "Epoch: 9 | Batch_idx: 670 |  Loss: (0.0061) | Acc: (99.81%) (26789/26840)\n",
      "Epoch: 9 | Batch_idx: 680 |  Loss: (0.0061) | Acc: (99.81%) (27188/27240)\n",
      "Epoch: 9 | Batch_idx: 690 |  Loss: (0.0060) | Acc: (99.81%) (27588/27640)\n",
      "Epoch: 9 | Batch_idx: 700 |  Loss: (0.0060) | Acc: (99.81%) (27988/28040)\n",
      "Epoch: 9 | Batch_idx: 710 |  Loss: (0.0060) | Acc: (99.81%) (28387/28440)\n",
      "Epoch: 9 | Batch_idx: 720 |  Loss: (0.0060) | Acc: (99.82%) (28787/28840)\n",
      "Epoch: 9 | Batch_idx: 730 |  Loss: (0.0060) | Acc: (99.82%) (29186/29240)\n",
      "Epoch: 9 | Batch_idx: 740 |  Loss: (0.0060) | Acc: (99.82%) (29586/29640)\n",
      "Epoch: 9 | Batch_idx: 750 |  Loss: (0.0059) | Acc: (99.82%) (29986/30040)\n",
      "Epoch: 9 | Batch_idx: 760 |  Loss: (0.0059) | Acc: (99.82%) (30385/30440)\n",
      "Epoch: 9 | Batch_idx: 770 |  Loss: (0.0059) | Acc: (99.82%) (30784/30840)\n",
      "Epoch: 9 | Batch_idx: 780 |  Loss: (0.0060) | Acc: (99.82%) (31183/31240)\n",
      "Epoch: 9 | Batch_idx: 790 |  Loss: (0.0059) | Acc: (99.82%) (31583/31640)\n",
      "Epoch: 9 | Batch_idx: 800 |  Loss: (0.0059) | Acc: (99.82%) (31983/32040)\n",
      "Epoch: 9 | Batch_idx: 810 |  Loss: (0.0059) | Acc: (99.82%) (32381/32440)\n",
      "Epoch: 9 | Batch_idx: 820 |  Loss: (0.0061) | Acc: (99.81%) (32779/32840)\n",
      "Epoch: 9 | Batch_idx: 830 |  Loss: (0.0063) | Acc: (99.81%) (33178/33240)\n",
      "Epoch: 9 | Batch_idx: 840 |  Loss: (0.0063) | Acc: (99.81%) (33577/33640)\n",
      "Epoch: 9 | Batch_idx: 850 |  Loss: (0.0063) | Acc: (99.81%) (33975/34040)\n",
      "Epoch: 9 | Batch_idx: 860 |  Loss: (0.0063) | Acc: (99.81%) (34373/34440)\n",
      "Epoch: 9 | Batch_idx: 870 |  Loss: (0.0065) | Acc: (99.80%) (34769/34840)\n",
      "Epoch: 9 | Batch_idx: 880 |  Loss: (0.0065) | Acc: (99.80%) (35168/35240)\n",
      "Epoch: 9 | Batch_idx: 890 |  Loss: (0.0065) | Acc: (99.80%) (35567/35640)\n",
      "Epoch: 9 | Batch_idx: 900 |  Loss: (0.0065) | Acc: (99.80%) (35967/36040)\n",
      "Epoch: 9 | Batch_idx: 910 |  Loss: (0.0064) | Acc: (99.80%) (36366/36440)\n",
      "Epoch: 9 | Batch_idx: 920 |  Loss: (0.0064) | Acc: (99.80%) (36766/36840)\n",
      "Epoch: 9 | Batch_idx: 930 |  Loss: (0.0064) | Acc: (99.80%) (37166/37240)\n",
      "Epoch: 9 | Batch_idx: 940 |  Loss: (0.0064) | Acc: (99.80%) (37565/37640)\n",
      "Epoch: 9 | Batch_idx: 950 |  Loss: (0.0063) | Acc: (99.80%) (37965/38040)\n",
      "Epoch: 9 | Batch_idx: 960 |  Loss: (0.0063) | Acc: (99.80%) (38364/38440)\n",
      "Epoch: 9 | Batch_idx: 970 |  Loss: (0.0064) | Acc: (99.80%) (38763/38840)\n",
      "Epoch: 9 | Batch_idx: 980 |  Loss: (0.0064) | Acc: (99.80%) (39161/39240)\n",
      "Epoch: 9 | Batch_idx: 990 |  Loss: (0.0064) | Acc: (99.80%) (39560/39640)\n",
      "Epoch: 9 | Batch_idx: 1000 |  Loss: (0.0065) | Acc: (99.80%) (39959/40040)\n",
      "Epoch: 9 | Batch_idx: 1010 |  Loss: (0.0065) | Acc: (99.80%) (40359/40440)\n",
      "Epoch: 9 | Batch_idx: 1020 |  Loss: (0.0064) | Acc: (99.80%) (40758/40840)\n",
      "Epoch: 9 | Batch_idx: 1030 |  Loss: (0.0064) | Acc: (99.80%) (41158/41240)\n",
      "Epoch: 9 | Batch_idx: 1040 |  Loss: (0.0066) | Acc: (99.80%) (41555/41640)\n",
      "Epoch: 9 | Batch_idx: 1050 |  Loss: (0.0066) | Acc: (99.80%) (41954/42040)\n",
      "Epoch: 9 | Batch_idx: 1060 |  Loss: (0.0066) | Acc: (99.80%) (42353/42440)\n",
      "Epoch: 9 | Batch_idx: 1070 |  Loss: (0.0065) | Acc: (99.80%) (42753/42840)\n",
      "Epoch: 9 | Batch_idx: 1080 |  Loss: (0.0065) | Acc: (99.80%) (43153/43240)\n",
      "Epoch: 9 | Batch_idx: 1090 |  Loss: (0.0065) | Acc: (99.80%) (43553/43640)\n",
      "Epoch: 9 | Batch_idx: 1100 |  Loss: (0.0064) | Acc: (99.80%) (43953/44040)\n",
      "Epoch: 9 | Batch_idx: 1110 |  Loss: (0.0064) | Acc: (99.80%) (44353/44440)\n",
      "Epoch: 9 | Batch_idx: 1120 |  Loss: (0.0064) | Acc: (99.81%) (44753/44840)\n",
      "Epoch: 9 | Batch_idx: 1130 |  Loss: (0.0063) | Acc: (99.81%) (45152/45240)\n",
      "Epoch: 9 | Batch_idx: 1140 |  Loss: (0.0063) | Acc: (99.81%) (45552/45640)\n",
      "Epoch: 9 | Batch_idx: 1150 |  Loss: (0.0063) | Acc: (99.81%) (45952/46040)\n",
      "Epoch: 9 | Batch_idx: 1160 |  Loss: (0.0062) | Acc: (99.81%) (46352/46440)\n",
      "Epoch: 9 | Batch_idx: 1170 |  Loss: (0.0062) | Acc: (99.81%) (46752/46840)\n",
      "Epoch: 9 | Batch_idx: 1180 |  Loss: (0.0062) | Acc: (99.81%) (47150/47240)\n",
      "Epoch: 9 | Batch_idx: 1190 |  Loss: (0.0062) | Acc: (99.81%) (47550/47640)\n",
      "Epoch: 9 | Batch_idx: 1200 |  Loss: (0.0062) | Acc: (99.81%) (47949/48040)\n",
      "Epoch: 9 | Batch_idx: 1210 |  Loss: (0.0062) | Acc: (99.81%) (48348/48440)\n",
      "Epoch: 9 | Batch_idx: 1220 |  Loss: (0.0061) | Acc: (99.81%) (48747/48840)\n",
      "Epoch: 9 | Batch_idx: 1230 |  Loss: (0.0061) | Acc: (99.81%) (49147/49240)\n",
      "Epoch: 9 | Batch_idx: 1240 |  Loss: (0.0061) | Acc: (99.81%) (49547/49640)\n",
      "=> saving checkpoint\n",
      "# TEST : Loss: (0.1953) | Acc: (95.57%) (9557/10000)\n",
      "1 hours 36 mins 9 secs for training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'                # GPU Number \n",
    "start_time = time.time()\n",
    "batch_size = 40\n",
    "learning_rate = 0.001\n",
    "root_dir = 'drive/app/cifar10/'\n",
    "default_directory = 'drive/app/torch/save_models'\n",
    "\n",
    "# Data Augmentation\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),               # Random Position Crop\n",
    "    transforms.RandomHorizontalFlip(),                  # right and left flip\n",
    "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010) )  # RGB Normalize Standard Deviation\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(size=(224, 224)),                               \n",
    "    transforms.ToTensor(),                              # change [0,255] Int value to [0,1] Float value\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010) )  # RGB Normalize Standard Deviation\n",
    "])\n",
    "\n",
    "# automatically download\n",
    "train_dataset = datasets.CIFAR10(root=root_dir,\n",
    "                                 train=True,\n",
    "                                 transform=transform_train,\n",
    "                                 download=True)\n",
    "\n",
    "test_dataset = datasets.CIFAR10(root=root_dir,\n",
    "                                train=False,\n",
    "                                transform=transform_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,            # at Training Procedure, Data Shuffle = True\n",
    "                                           num_workers=4)           # CPU loader number\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False,            # at Test Procedure, Data Shuffle = False\n",
    "                                          num_workers=4)            # CPU loader number\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "def initialize_model( num_classes, use_pretrained=True):\n",
    "\n",
    "    model_ft = models.vgg19_bn(pretrained=use_pretrained)\n",
    "    num_ftrs = model_ft.classifier[6].in_features\n",
    "    model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
    "    input_size = 224\n",
    "    return model_ft, input_size\n",
    "\n",
    "# Initialize the model for this run\n",
    "model, input_size = initialize_model(10, use_pretrained=True)\n",
    "'''\n",
    "#loading Pretrainined VGG\n",
    "model= models.vgg16(pretrained=True)\n",
    "model.classifier[6] = nn.Linear(4096, 10)\n",
    "\n",
    "'''\n",
    "model = model.to(device)\n",
    "#optim.Adam(model.parameters(), lr=0.01, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)\n",
    "optimizer = optim.Adagrad(model.parameters(), lr=0.01, lr_decay=0, weight_decay=0, initial_accumulator_value=0, eps=1e-10) #Changed the optimizer to Adagrad \n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "if torch.cuda.device_count() > 0:\n",
    "    print(\"USE\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    model = nn.DataParallel(model).cuda()\n",
    "    cudnn.benchmark = True\n",
    "else:\n",
    "    print(\"USE ONLY CPU!\")\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    train_loss = 0 \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "        else:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target.data).cpu().sum()\n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Epoch: {} | Batch_idx: {} |  Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
    "                  .format(epoch, batch_idx, train_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = Variable(data.cuda()), Variable(target.cuda())\n",
    "        else:\n",
    "            data, target = Variable(data), Variable(target)\n",
    "\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target.data).cpu().sum()\n",
    "    print('# TEST : Loss: ({:.4f}) | Acc: ({:.2f}%) ({}/{})'\n",
    "          .format(test_loss / (batch_idx + 1), 100. * correct / total, correct, total))\n",
    "\n",
    "\n",
    "def save_checkpoint(directory, state, filename='latest.tar.gz'):\n",
    "\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    model_filename = os.path.join(directory, filename)\n",
    "    torch.save(state, model_filename)\n",
    "    print(\"=> saving checkpoint\")\n",
    "\n",
    "def load_checkpoint(directory, filename='latest.tar.gz'):\n",
    "\n",
    "    model_filename = os.path.join(directory, filename)\n",
    "    if os.path.exists(model_filename):\n",
    "        print(\"=> loading checkpoint\")\n",
    "        state = torch.load(model_filename)\n",
    "        return state\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "start_epoch = 0\n",
    "\n",
    "checkpoint = load_checkpoint(default_directory)\n",
    "if not checkpoint:\n",
    "    pass\n",
    "else:\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "for epoch in range(start_epoch, 10):\n",
    "\n",
    "    if epoch < 20:\n",
    "        lr = learning_rate\n",
    "    elif epoch < 40:\n",
    "        lr = learning_rate * 0.1\n",
    "    else:\n",
    "        lr = learning_rate * 0.01\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    train(epoch)\n",
    "    save_checkpoint(default_directory, {\n",
    "        'epoch': epoch,\n",
    "        'model': model,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    })\n",
    "    test()  \n",
    "\n",
    "now = time.gmtime(time.time() - start_time)\n",
    "print('{} hours {} mins {} secs for training'.format(now.tm_hour, now.tm_min, now.tm_sec))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5789.894215,
   "end_time": "2021-12-09T09:30:32.156493",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-09T07:54:02.262278",
   "version": "2.3.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0c5fe92a451541e18f75c6e290338100": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2819958b54b746f5b683b06c5f08f78f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_50e39579cba548cda5eb36644d35630e",
       "placeholder": "",
       "style": "IPY_MODEL_46c704d2ea814777a7a008ea2344904d",
       "value": "100%"
      }
     },
     "30e9979b05e94623838cafc1278aba08": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "3cea93a4d51e441f9d9b80ab0a72a4df": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "46c704d2ea814777a7a008ea2344904d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "4bd44b36d02449e29faad0299555fb08": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "50e39579cba548cda5eb36644d35630e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6bdb04333e88431dbd08e97905ea53b0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "70ff106e947541bba9d47f18db255a76": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_77e0a5a41a6c42d78491c3abac44c728",
        "IPY_MODEL_8782a0d7a24547fc9105755c6c4d3586",
        "IPY_MODEL_abd94e96833743edaa0f5463ed7d4924"
       ],
       "layout": "IPY_MODEL_0c5fe92a451541e18f75c6e290338100"
      }
     },
     "77e0a5a41a6c42d78491c3abac44c728": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_92dc7c4a03f940249f553b1ae649ba56",
       "placeholder": "",
       "style": "IPY_MODEL_cf07621e02634231be69f0c2a8601ef4",
       "value": ""
      }
     },
     "7c1af14ff8e24a4299e01ebc8b267d73": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8782a0d7a24547fc9105755c6c4d3586": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ab43a34f99964fa2891a3129bb430f6c",
       "max": 170498071.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9b332929ffd5410abcccedadb0f786e1",
       "value": 170498071.0
      }
     },
     "92dc7c4a03f940249f553b1ae649ba56": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9311ddb0ab46418f9894014a5da6be19": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2819958b54b746f5b683b06c5f08f78f",
        "IPY_MODEL_b18ddfc23c6a4ae298c2c8e708941a47",
        "IPY_MODEL_cffc4a26b04a4159bc7457ce21d617da"
       ],
       "layout": "IPY_MODEL_4bd44b36d02449e29faad0299555fb08"
      }
     },
     "932b758592834c97882d46445eb7d51d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b332929ffd5410abcccedadb0f786e1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a79f2ba681824acbb822db5b0764cace": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "ab43a34f99964fa2891a3129bb430f6c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "abd94e96833743edaa0f5463ed7d4924": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3cea93a4d51e441f9d9b80ab0a72a4df",
       "placeholder": "",
       "style": "IPY_MODEL_a79f2ba681824acbb822db5b0764cace",
       "value": " 170499072/? [00:05&lt;00:00, 31733632.77it/s]"
      }
     },
     "b18ddfc23c6a4ae298c2c8e708941a47": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_932b758592834c97882d46445eb7d51d",
       "max": 574769405.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_6bdb04333e88431dbd08e97905ea53b0",
       "value": 574769405.0
      }
     },
     "cf07621e02634231be69f0c2a8601ef4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cffc4a26b04a4159bc7457ce21d617da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7c1af14ff8e24a4299e01ebc8b267d73",
       "placeholder": "",
       "style": "IPY_MODEL_30e9979b05e94623838cafc1278aba08",
       "value": " 548M/548M [00:19&lt;00:00, 31.6MB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
